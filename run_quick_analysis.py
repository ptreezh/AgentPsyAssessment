#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿåˆ†æè„šæœ¬ - åŸºäºç°æœ‰è¯„ä¼°ç»“æœç”ŸæˆæŠ¥å‘Š
"""

import json
import os
from pathlib import Path
from datetime import datetime

def generate_analysis_report():
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    print("ğŸ“Š å¼€å§‹ç”Ÿæˆè¯„ä¼°åˆ†ææŠ¥å‘Š...")
    
    # è¯»å–å½“å‰åˆ†ææ‘˜è¦
    summary_file = "current_analysis_summary.json"
    if not os.path.exists(summary_file):
        print(f"âŒ æœªæ‰¾åˆ°åˆ†ææ‘˜è¦æ–‡ä»¶: {summary_file}")
        return
    
    with open(summary_file, 'r', encoding='utf-8') as f:
        summary = json.load(f)
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report = {
        "report_timestamp": datetime.now().isoformat(),
        "analysis_summary": summary,
        "recommendations": {
            "model_priority": ["deepseek-v3.2-exp", "qwen-max", "Moonshot-Kimi-K2-Instruct"],
            "improvement_areas": [
                "æé«˜å¼€æ”¾æ€§ç»´åº¦è¯„ä¼°å‡†ç¡®æ€§",
                "é…ç½®æœ¬åœ°è¯„ä¼°å™¨ä»¥æå‡ç¨³å®šæ€§",
                "ä¼˜åŒ–å¤šæ¨¡å‹ä¸€è‡´æ€§ç®—æ³•",
                "å¢åŠ è¯„ä¼°æ–‡ä»¶æ•°é‡ä»¥è·å–æ›´å¯é ç»Ÿè®¡"
            ],
            "next_steps": [
                "å®ç°æœ¬åœ°è¯„ä¼°å™¨é…ç½®",
                "å®Œæˆè½¬æ¢/ç®€åŒ–è¿‡æ»¤å™¨",
                "ä¼˜åŒ–æ•°æ®å¤„ç†æµç¨‹",
                "å¢åŠ æ›´å¤šæµ‹è¯•æ–‡ä»¶åˆ†æ"
            ]
        },
        "performance_metrics": {
            "total_files": summary["summary"]["total_files_analyzed"],
            "success_rate": summary["summary"]["successful_analyses"] / 
                          (summary["summary"]["successful_analyses"] + summary["summary"]["failed_analyses"]),
            "model_consistency": "é«˜ (MBTIç±»å‹100%ä¸€è‡´)",
            "big5_variance": "ä½ (é™¤å¼€æ”¾æ€§å¤–ï¼Œå…¶ä»–ç»´åº¦é«˜åº¦ä¸€è‡´)"
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = f"quick_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    # è¾“å‡ºå…³é”®æŒ‡æ ‡
    print("\nğŸ“ˆ å…³é”®è¯„ä¼°æŒ‡æ ‡:")
    print(f"   - æ€»åˆ†ææ–‡ä»¶: {report['performance_metrics']['total_files']}")
    print(f"   - æˆåŠŸç‡: {report['performance_metrics']['success_rate']:.1%}")
    print(f"   - æ¨¡å‹ä¸€è‡´æ€§: {report['performance_metrics']['model_consistency']}")
    print(f"   - Big5æ–¹å·®: {report['performance_metrics']['big5_variance']}")
    
    return report

def check_pending_tasks():
    """æ£€æŸ¥å¾…åŠä»»åŠ¡çŠ¶æ€"""
    print("\nğŸ“‹ å¾…åŠä»»åŠ¡çŠ¶æ€æ£€æŸ¥:")
    
    tasks = [
        ("è½¬æ¢/ç®€åŒ–è¿‡æ»¤å™¨å®ç°", "convert_assessment_format.py"),
        ("æœ¬åœ°è¯„ä¼°äº§ç‰©å®ç°", "shared_analysis/analyze_results.py"),
        ("Ollamaé…ç½®", "config/ollama_config.json"),
        ("è¿›åº¦ç›‘æ§", "monitor_batch_progress.py")
    ]
    
    for task_name, file_path in tasks:
        if os.path.exists(file_path):
            status = "âœ… å­˜åœ¨"
        else:
            status = "âŒ ç¼ºå¤±"
        print(f"   - {task_name}: {status} ({file_path})")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¿«é€Ÿè¯„ä¼°åˆ†æ")
    print("=" * 50)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_analysis_report()
    
    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
    check_pending_tasks()
    
    print("\nğŸ¯ å»ºè®®ä¸‹ä¸€æ­¥:")
    print("1. é…ç½®æœ¬åœ°Ollamaè¯„ä¼°å™¨")
    print("2. ä¼˜åŒ–æ•°æ®å¤„ç†æµç¨‹")
    print("3. è¿è¡Œæ‰¹é‡åˆ†æå¤„ç†æ›´å¤šæ–‡ä»¶")
    print("4. éªŒè¯å¤šæ¨¡å‹ä¸€è‡´æ€§ç®—æ³•")

if __name__ == "__main__":
    main()