# 分段可信评估系统 - TDD测试用例

## 1. 单元测试

### 1.1 分段功能测试 (Test Segmented Scoring)

#### 1.1.1 测试用例：test_create_segments
- **目的**: 验证问题列表是否能正确分段
- **输入**: 包含50个问题的列表，分段大小为2
- **预期输出**: 25个段，每段包含2个问题
- **边界条件**: 
  - 分段大小大于问题总数
  - 问题总数不能被分段大小整除
  - 空列表输入

#### 1.1.2 测试用例：test_segment_prompt_creation
- **目的**: 验证分段评分提示是否正确生成
- **输入**: 包含2个问题的段，段号，总段数
- **预期输出**: 格式正确的提示文本，包含所有必要信息
- **验证点**:
  - 问题内容正确包含
  - 段号和总段数信息正确
  - 评分标准明确

#### 1.1.3 测试用例：test_score_validation
- **目的**: 验证评分是否符合1-3-5分制
- **输入**: 各种评分值 (包括1,2,3,4,5及其他数值)
- **预期输出**: 2和4修正为3，其他超出范围值正确修正
- **验证点**:
  - 1,3,5保持不变
  - 2,4修正为3
  - 超出范围值按规则修正

### 1.2 多评估器功能测试 (Test Multi-Evaluator Scoring)

#### 1.2.1 测试用例：test_model_selection
- **目的**: 验证评估器列表是否按优先级正确选择
- **输入**: 模型配置列表
- **预期输出**: 模型按配置优先级排序
- **验证点**:
  - 云模型和本地模型正确排序
  - 有效模型被正确选择

#### 1.2.2 测试用例：test_evaluator_fallback
- **目的**: 验证单个评估器失败时是否正确切换
- **输入**: 失败的评估器模型
- **预期输出**: 自动切换到下一个可用评估器
- **验证点**:
  - 失败后自动重试
  - 不影响整体处理流程

#### 1.2.3 测试用例：test_multi_evaluator_consistency
- **目的**: 验证多个评估器对同一段的评分一致性
- **输入**: 同一段交由3个不同评估器
- **预期输出**: 生成3套独立评分结果
- **验证点**:
  - 每个评估器生成独立结果
  - 结果格式符合规范

### 1.3 争议解决功能测试 (Test Dispute Resolution)

#### 1.3.1 测试用例：test_dispute_identification
- **目的**: 验证争议识别算法是否正确工作
- **输入**: 包含不同评分的多评估器结果
- **预期输出**: 正确识别评分差异>1的项目
- **验证点**:
  - 正确识别争议项目
  - 低于阈值的差异不被标记为争议

#### 1.3.2 测试用例：test_additional_evaluator_assignment
- **目的**: 验证在争议情况下是否正确分配额外评估器
- **输入**: 包含争议的评估结果
- **预期输出**: 启动2个额外评估器处理争议
- **验证点**:
  - 为争议项目分配额外评估
  - 不影响非争议项目

#### 1.3.3 测试用例：test_dispute_resolution_rounds
- **目的**: 验证多轮争议解决机制
- **输入**: 需要多轮解决的争议问题
- **预期输出**: 最多进行3轮争议解决
- **验证点**:
  - 每轮正确添加评估器
  - 达到最大轮次后停止

#### 1.3.4 测试用例：test_majority_decision_algorithm
- **目的**: 验证多数决策算法是否正确
- **输入**: 包含多个评分的争议项目
- **预期输出**: 去除最高分和最低分后取中位数
- **验证点**:
  - 正确去除极值
  - 中位数计算准确

### 1.4 一致性分析测试 (Test Consistency Analysis)

#### 1.4.1 测试用例：test_consistency_calculation
- **目的**: 验证一致性计算是否正确
- **输入**: 多模型评分结果
- **预期输出**: 准确的一致性百分比
- **验证点**:
  - 每个维度一致性正确计算
  - 总体一致性正确计算

#### 1.4.2 测试用例：test_consistency_levels
- **目的**: 验证一致性等级划分是否正确
- **输入**: 不同评分范围的测试数据
- **预期输出**: 按规范等级划分 (完全一致、高度一致等)
- **验证点**:
  - 范围≤1: 完全一致
  - 范围≤2: 高度一致
  - 范围≤3: 中等一致
  - 范围>3: 差异较大

### 1.5 信度验证测试 (Test Reliability Validation)

#### 1.5.1 测试用例：test_cronbach_alpha_calculation
- **目的**: 验证Cronbach's Alpha系数计算
- **输入**: 评分矩阵 (评估器×题目)
- **预期输出**: 0-1之间的信度系数
- **验证点**:
  - 计算公式正确
  - 结果在有效范围内

#### 1.5.2 测试用例：test_inter_rater_reliability
- **目的**: 验证评估者间信度计算
- **输入**: 多评估器对同一特质的评分
- **预期输出**: 信度系数
- **验证点**:
  - 标准差计算正确
  - 一致性指标准确

#### 1.5.3 测试用例：test_reliability_threshold_validation
- **目的**: 验证信度阈值验证功能
- **输入**: 各种信度值
- **预期输出**: 信度≥0.8为通过
- **验证点**:
  - 正确判断通过/失败
  - 生成验证报告

### 1.6 人格分析测试 (Test Personality Analysis)

#### 1.6.1 测试用例：test_big5_analysis
- **目的**: 验证大五人格分析是否正确
- **输入**: 50题汇总评分
- **预期输出**: Big5五个维度得分及解释
- **验证点**:
  - 五个维度得分正确计算
  - 得分在合理范围内

#### 1.6.2 测试用例：test_mbti_mapping
- **目的**: 验证MBTI类型映射是否可行
- **输入**: Big5维度得分
- **预期输出**: 推断的MBTI类型
- **验证点**:
  - 映射逻辑合理
  - 输出有效MBTI类型

### 1.7 报告管理测试 (Test Report Management)

#### 1.7.1 测试用例：test_report_completion_marking
- **目的**: 验证报告完成标记是否正确
- **输入**: 完成评估的报告
- **预期输出**: 正确标记为已完成
- **验证点**:
  - 文件标记正确
  - 状态信息准确

#### 1.7.2 测试用例：test_file_moving_functionality
- **目的**: 验证文件移动功能
- **输入**: 已完成评估的原始文件
- **预期输出**: 文件移动到指定目录
- **验证点**:
  - 源文件正确移动
  - 目标目录正确

## 2. 集成测试

### 2.1 端到端处理测试 (End-to-End Processing Test)

#### 2.1.1 测试用例：test_full_assessment_workflow
- **目的**: 验证整个评估工作流
- **输入**: 原始测评报告文件
- **预期输出**: 完整的评估结果文件
- **验证点**:
  - 所有处理步骤正确执行
  - 输出文件符合规范

#### 2.1.2 测试用例：test_dispute_resolution_workflow
- **目的**: 验证争议解决完整流程
- **输入**: 包含争议的评估数据
- **预期输出**: 争议得到解决的最终结果
- **验证点**:
  - 争议正确识别
  - 多轮解决按序执行
  - 最终结果符合多数决策原则

### 2.2 错误处理测试 (Error Handling Test)

#### 2.2.1 测试用例：test_api_failure_handling
- **目的**: 验证API失败时的处理
- **输入**: 无法访问的API模型
- **预期输出**: 自动切换到备用模型
- **验证点**:
  - 正确检测API失败
  - 自动切换机制工作正常

#### 2.2.2 测试用例：test_json_parsing_failure
- **目的**: 验证JSON解析失败时的处理
- **输入**: 格式错误的JSON响应
- **预期输出**: 适当错误处理和重试
- **验证点**:
  - 错误被正确处理
  - 不影响其他处理流程

#### 2.2.3 测试用例：test_large_file_handling
- **目的**: 验证大文件的分段处理
- **输入**: 超出模型上下文的长文件
- **预期输出**: 正确分段处理
- **验证点**:
  - 文件被正确分段
  - 每段独立处理
  - 结果正确汇总

## 3. 性能测试

### 3.1 处理时间测试
- **目的**: 验证单文件处理时间符合标准(<10分钟)
- **测试方法**: 记录完整处理时间

### 3.2 内存使用测试
- **目的**: 验证内存使用符合标准(<1GB)
- **测试方法**: 监控处理过程中的内存使用

### 3.3 批量处理测试
- **目的**: 验证批量处理性能
- **测试方法**: 批量处理多个文件，记录总体性能指标

## 4. 验收标准

### 4.1 功能验收
- 所有单元测试通过率≥95%
- 所有集成测试通过率≥90%
- 符合需求规范的所有功能点

### 4.2 质量验收
- 信度≥0.8
- 一致性≥60%
- 成功率≥95%

### 4.3 性能验收
- 单文件处理时间<10分钟
- 内存使用<1GB
- 批量处理稳定性

## 5. 测试数据准备

### 5.1 标准测试数据
- 创建包含50个问题的标准测试文件
- 包含各种类型的回答(开放性、尽责性等)

### 5.2 边界条件测试数据
- 空回答
- 超长回答
- 格式异常的回答

### 5.3 争议场景测试数据
- 故意创建评分差异较大的案例
- 用于验证争议解决机制