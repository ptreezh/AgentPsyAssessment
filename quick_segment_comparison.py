#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå•æ–‡ä»¶2é¢˜vs5é¢˜åˆ†æ®µå¯¹æ¯”æµ‹è¯•
"""

import sys
import os
import json
import time
from pathlib import Path
from datetime import datetime
import statistics

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONUNBUFFERED'] = '1'
os.environ['DASHSCOPE_API_KEY'] = 'sk-ded837735b3c44599a9bc138da561c27'

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def quick_comparison_test():
    """å¿«é€Ÿå¯¹æ¯”æµ‹è¯•"""
    print("ğŸ”¬ å¿«é€Ÿ2é¢˜vs5é¢˜åˆ†æ®µå¯¹æ¯”æµ‹è¯•")
    print("=" * 50)

    # é€‰æ‹©æµ‹è¯•æ–‡ä»¶
    test_file = "results/results/asses_deepseek_r1_70b_agent_big_five_50_complete2_a10_e0_t0_0_09271.json"

    if not os.path.exists(test_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return

    # è¯»å–æ–‡ä»¶
    with open(test_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # æå–å‰10é¢˜
    questions = []
    if 'assessment_results' in data and isinstance(data['assessment_results'], list):
        for item in data['assessment_results'][:10]:
            if isinstance(item, dict) and 'question_data' in item:
                question_data = item['question_data']
                if isinstance(question_data, dict):
                    question_text = question_data.get('prompt_for_agent', '')
                    answer_text = item.get('extracted_response', '')

                    if question_text and answer_text:
                        questions.append({
                            'question': question_text,
                            'answer': answer_text
                        })

    print(f"ğŸ“‹ æå–äº† {len(questions)} ä¸ªé—®é¢˜")

    if len(questions) < 10:
        print("âŒ é—®é¢˜æ•°é‡ä¸è¶³")
        return

    # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
    import openai
    client = openai.OpenAI(
        api_key=os.getenv('DASHSCOPE_API_KEY'),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    def analyze_segments(segment_size: int, segment_name: str):
        """åˆ†ææŒ‡å®šå¤§å°çš„åˆ†æ®µ"""
        print(f"\nğŸ” {segment_name}åˆ†æ®µåˆ†æ:")

        # åˆ†æ®µ
        segments = []
        for i in range(0, len(questions), segment_size):
            segment = questions[i:i+segment_size]
            if len(segment) == segment_size:
                segments.append(segment)

        print(f"  ğŸ“Š åˆ†æˆ {len(segments)} ä¸ª{segment_size}é¢˜åˆ†æ®µ")

        # åˆ†ææ¯ä¸ªåˆ†æ®µ
        segment_results = []
        for i, segment in enumerate(segments, 1):
            print(f"    åˆ†æåˆ†æ®µ{i}...")

            # æ„å»ºæç¤º
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„å¿ƒç†è¯„ä¼°åˆ†æå¸ˆã€‚åˆ†æä»¥ä¸‹{segment_size}ä¸ªé—®é¢˜çš„å›ç­”ï¼Œè¯„ä¼°Big5äººæ ¼ç‰¹è´¨ã€‚

ä¸¥æ ¼è¯„åˆ†æ ‡å‡†ï¼š
- 1åˆ†ï¼šæä½è¡¨ç°
- 3åˆ†ï¼šä¸­ç­‰è¡¨ç°
- 5åˆ†ï¼šæé«˜è¡¨ç°

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
  "success": true,
  "scores": {{
    "openness_to_experience": 1æˆ–3æˆ–5,
    "conscientiousness": 1æˆ–3æˆ–5,
    "extraversion": 1æˆ–3æˆ–5,
    "agreeableness": 1æˆ–3æˆ–5,
    "neuroticism": 1æˆ–3æˆ–5
  }}
}}

ç¬¬{i}æ®µå†…å®¹ï¼š
"""

            for j, item in enumerate(segment, 1):
                prompt += f"\né—®é¢˜{j}: {item['question'][:100]}..."
                prompt += f"\nå›ç­”{j}: {item['answer'][:100]}...\n"

            try:
                response = client.chat.completions.create(
                    model="qwen-long",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0.1
                )

                content = response.choices[0].message.content

                # è§£æJSON
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    result = json.loads(json_str)

                    if 'scores' in result:
                        scores = result['scores']
                        print(f"      âœ… è¯„åˆ†: {scores}")

                        # éªŒè¯è¯„åˆ†æ ‡å‡†
                        invalid_scores = [s for s in scores.values() if s not in [1, 3, 5]]
                        if invalid_scores:
                            print(f"      âš ï¸ å‘ç°æ— æ•ˆè¯„åˆ†: {invalid_scores}")
                            # ä¿®æ­£æ— æ•ˆè¯„åˆ†
                            for trait, score in scores.items():
                                if score not in [1, 3, 5]:
                                    if score < 2:
                                        scores[trait] = 1
                                    elif score > 4:
                                        scores[trait] = 5
                                    else:
                                        scores[trait] = 3
                            print(f"      ğŸ”§ ä¿®æ­£å: {scores}")

                        segment_results.append(result)
                    else:
                        print(f"      âŒ æ— scoreså­—æ®µ")
                else:
                    print(f"      âŒ JSONè§£æå¤±è´¥")

            except Exception as e:
                print(f"      âŒ åˆ†æå¤±è´¥: {e}")

            time.sleep(2)  # APIé™åˆ¶

        if segment_results:
            # è®¡ç®—æœ€ç»ˆè¯„åˆ†
            final_scores = {}
            for trait in ['openness_to_experience', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']:
                all_scores = []
                for result in segment_results:
                    if result['scores'] and trait in result['scores']:
                        all_scores.append(result['scores'][trait])

                if all_scores:
                    final_scores[trait] = int(statistics.median(all_scores))
                else:
                    final_scores[trait] = 3  # é»˜è®¤å€¼

            print(f"  ğŸ“Š æœ€ç»ˆè¯„åˆ†: {final_scores}")
            return final_scores
        else:
            print(f"  âŒ æ²¡æœ‰æˆåŠŸçš„åˆ†æ®µç»“æœ")
            return None

    # æ‰§è¡Œå¯¹æ¯”åˆ†æ
    print(f"\nğŸ¯ å¼€å§‹å¯¹æ¯”åˆ†æ...")

    # 2é¢˜åˆ†æ®µåˆ†æ
    scores_2segment = analyze_segments(2, "2é¢˜")

    # 5é¢˜åˆ†æ®µåˆ†æ
    scores_5segment = analyze_segments(5, "5é¢˜")

    if scores_2segment and scores_5segment:
        # è®¡ç®—ä¸€è‡´æ€§
        print(f"\nğŸ“ˆ ä¸€è‡´æ€§åˆ†æ:")
        print("-" * 40)

        traits = ['openness_to_experience', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']

        exact_matches = 0
        close_matches = 0

        for trait in traits:
            score_2 = scores_2segment[trait]
            score_5 = scores_5segment[trait]
            difference = abs(score_2 - score_5)

            exact_match = score_2 == score_5
            close_match = difference <= 2

            if exact_match:
                exact_matches += 1
                status = "âœ… å®Œå…¨ä¸€è‡´"
            elif close_match:
                close_matches += 1
                status = "âš ï¸ æ¥è¿‘ä¸€è‡´"
            else:
                status = "âŒ å·®å¼‚è¾ƒå¤§"

            print(f"  {trait}: 2é¢˜={score_2}, 5é¢˜={score_5}, å·®å¼‚={difference} {status}")

        # è®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡
        total_traits = len(traits)
        exact_match_rate = (exact_matches / total_traits) * 100
        close_match_rate = (close_matches / total_traits) * 100
        consistency_score = (exact_match_rate * 0.7 + close_match_rate * 0.3)

        print(f"\nğŸ¯ ä¸€è‡´æ€§ç»Ÿè®¡:")
        print(f"  âœ… å®Œå…¨åŒ¹é…: {exact_matches}/{total_traits} ({exact_match_rate:.1f}%)")
        print(f"  âš ï¸ æ¥è¿‘åŒ¹é…: {close_matches}/{total_traits} ({close_match_rate:.1f}%)")
        print(f"  ğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {consistency_score:.1f}/100")

        # è¯„ä¼°ç»“æœ
        if consistency_score >= 80:
            reliability = "ä¼˜ç§€"
            recommendation = "âœ… 5é¢˜åˆ†æ®µä¿¡åº¦ä¼˜ç§€ï¼Œå¯ä»¥æ›¿ä»£2é¢˜åˆ†æ®µ"
        elif consistency_score >= 70:
            reliability = "è‰¯å¥½"
            recommendation = "âš ï¸ 5é¢˜åˆ†æ®µä¿¡åº¦è‰¯å¥½ï¼Œå»ºè®®ç»“åˆä½¿ç”¨"
        elif consistency_score >= 60:
            reliability = "ä¸­ç­‰"
            recommendation = "âš ï¸ 5é¢˜åˆ†æ®µä¿¡åº¦ä¸­ç­‰ï¼Œéœ€è¦ä¼˜åŒ–"
        else:
            reliability = "éœ€è¦æ”¹è¿›"
            recommendation = "âŒ 5é¢˜åˆ†æ®µä¿¡åº¦ä¸è¶³ï¼Œå»ºè®®ç»§ç»­ä½¿ç”¨2é¢˜åˆ†æ®µ"

        print(f"\nğŸ† ä¿¡åº¦è¯„çº§: {reliability}")
        print(f"ğŸ’¡ å»ºè®®: {recommendation}")

        # ä¿å­˜ç»“æœ
        result_data = {
            "test_info": {
                "test_file": Path(test_file).name,
                "test_date": datetime.now().isoformat(),
                "questions_used": len(questions)
            },
            "scores_2segment": scores_2segment,
            "scores_5segment": scores_5segment,
            "consistency_analysis": {
                "exact_match_rate": exact_match_rate,
                "close_match_rate": close_match_rate,
                "consistency_score": consistency_score,
                "reliability_rating": reliability,
                "recommendation": recommendation
            }
        }

        with open("quick_segment_comparison_result.json", 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: quick_segment_comparison_result.json")

        return result_data
    else:
        print("âŒ å¯¹æ¯”åˆ†æå¤±è´¥")
        return None

if __name__ == "__main__":
    quick_comparison_test()