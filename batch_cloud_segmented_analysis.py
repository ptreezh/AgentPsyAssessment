#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡äº‘è¯„ä¼°å™¨åˆ†æ®µå¼å¿ƒç†è¯„ä¼°åˆ†æå™¨
ä½¿ç”¨Qwenäº‘æ¨¡å‹å¯¹å¤šä¸ªæµ‹è¯„æŠ¥å‘Šè¿›è¡Œåˆ†æ®µå¤„ç†ï¼Œç”Ÿæˆæ ‡å‡†åŒ–çš„1-3-5è¯„åˆ†Big5è¯„ä¼°
"""

import json
import sys
import time
import argparse
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from cloud_segmented_analysis import CloudSegmentedPersonalityAnalyzer

class BatchCloudSegmentedAnalyzer:
    """æ‰¹é‡äº‘è¯„ä¼°å™¨åˆ†æ®µåˆ†æå™¨"""

    def __init__(self, model: str = "qwen-long", api_key: str = None, max_workers: int = 2):
        self.model = model
        self.api_key = api_key or "sk-ffd03518254b495b8d27e723cd413fc1"
        self.max_workers = max_workers
        self.results = []

    def analyze_single_file(self, input_file: Path, output_dir: Path) -> dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            print(f"ğŸ” å¼€å§‹åˆ†æ: {input_file.name}")

            # åˆ›å»ºåˆ†æå™¨
            analyzer = CloudSegmentedPersonalityAnalyzer(
                model=self.model,
                api_key=self.api_key
            )

            # æ‰§è¡Œåˆ†æ
            result = analyzer.analyze_full_assessment(str(input_file))

            # ä¿å­˜ç»“æœ
            output_file = output_dir / f"{input_file.stem}_{self.model}_segmented.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            # ç”Ÿæˆæ‘˜è¦
            big5_scores = result['big_five_final_scores']
            summary = {
                'file': str(input_file),
                'output_file': str(output_file),
                'model': self.model,
                'success': True,
                'big5_final_scores': {trait: data['final_score'] for trait, data in big5_scores.items()},
                'mbti_type': result['mbti_assessment']['type'],
                'total_questions': result['file_info']['total_questions'],
                'segments_processed': result['file_info']['segments_count']
            }

            print(f"âœ… åˆ†æå®Œæˆ: {input_file.name}")
            print(f"   Big5: {summary['big5_final_scores']}")
            print(f"   MBTI: {summary['mbti_type']}")
            print(f"   è¾“å‡º: {output_file.name}")

            return summary

        except Exception as e:
            error_summary = {
                'file': str(input_file),
                'output_file': None,
                'model': self.model,
                'success': False,
                'error': str(e),
                'big5_final_scores': {},
                'mbti_type': None,
                'total_questions': 0,
                'segments_processed': 0
            }

            print(f"âŒ åˆ†æå¤±è´¥: {input_file.name} - {e}")
            return error_summary

    def analyze_batch(self, input_files: list[Path], output_dir: Path,
                     progress_callback=None) -> list[dict]:
        """æ‰¹é‡åˆ†ææ–‡ä»¶"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ {len(input_files)} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model}")
        print(f"âš¡ å¹¶å‘æ•°: {self.max_workers}")

        output_dir.mkdir(parents=True, exist_ok=True)

        results = []
        completed = 0

        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.analyze_single_file, file, output_dir): file
                for file in input_files
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)
                    completed += 1

                    if progress_callback:
                        progress_callback(completed, len(input_files), result)

                    # æ˜¾ç¤ºè¿›åº¦
                    success = "âœ…" if result['success'] else "âŒ"
                    print(f"[{completed}/{len(input_files)}] {success} {file.name}")

                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                    time.sleep(2)

                except Exception as e:
                    print(f"âŒ å¤„ç† {file.name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    results.append({
                        'file': str(file),
                        'success': False,
                        'error': str(e)
                    })

        return results

    def generate_summary_report(self, results: list[dict], output_dir: Path):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        successful_results = [r for r in results if r['success']]
        failed_results = [r for r in results if not r['success']]

        # ç»Ÿè®¡Big5è¯„åˆ†åˆ†å¸ƒ
        big5_stats = {}
        mbti_stats = {}

        for result in successful_results:
            # Big5ç»Ÿè®¡
            for trait, score in result['big5_final_scores'].items():
                if trait not in big5_stats:
                    big5_stats[trait] = {1: 0, 3: 0, 5: 0}
                big5_stats[trait][score] += 1

            # MBTIç»Ÿè®¡
            mbti_type = result['mbti_type']
            if mbti_type not in mbti_stats:
                mbti_stats[mbti_type] = 0
            mbti_stats[mbti_type] += 1

        # ç”Ÿæˆæ±‡æ€»æ•°æ®
        summary = {
            'summary': {
                'total_files': len(results),
                'successful': len(successful_results),
                'failed': len(failed_results),
                'success_rate': len(successful_results) / len(results) * 100 if results else 0,
                'model_used': self.model,
                'analysis_timestamp': datetime.now().isoformat()
            },
            'big5_distribution': big5_stats,
            'mbti_distribution': mbti_stats,
            'detailed_results': results
        }

        # ä¿å­˜JSONæ±‡æ€»
        json_summary = output_dir / f"batch_summary_{self.model}.json"
        with open(json_summary, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_content = f"""# æ‰¹é‡äº‘è¯„ä¼°å™¨åˆ†æ®µåˆ†ææŠ¥å‘Š

**åˆ†ææ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ä½¿ç”¨æ¨¡å‹:** {self.model}
**è¯„åˆ†æ ‡å‡†:** 1-3-5 (1=ä½, 3=ä¸­, 5=é«˜)

## æ±‡æ€»ç»Ÿè®¡

- **æ€»æ–‡ä»¶æ•°:** {len(results)}
- **æˆåŠŸåˆ†æ:** {len(successful_results)}
- **å¤±è´¥åˆ†æ:** {len(failed_results)}
- **æˆåŠŸç‡:** {summary['summary']['success_rate']:.1f}%

## Big5è¯„åˆ†åˆ†å¸ƒ

"""

        for trait, scores in big5_stats.items():
            total = sum(scores.values())
            md_content += f"### {trait.replace('_', ' ').title()}\n"
            md_content += f"- 1åˆ† (ä½): {scores[1]} ({scores[1]/total*100:.1f}%)\n"
            md_content += f"- 3åˆ† (ä¸­): {scores[3]} ({scores[3]/total*100:.1f}%)\n"
            md_content += f"- 5åˆ† (é«˜): {scores[5]} ({scores[5]/total*100:.1f}%)\n\n"

        md_content += "## MBTIç±»å‹åˆ†å¸ƒ\n\n"

        for mbti_type, count in sorted(mbti_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(successful_results) * 100
            md_content += f"- **{mbti_type}:** {count} ({percentage:.1f}%)\n"

        md_content += "\n## è¯¦ç»†ç»“æœ\n\n"

        for result in successful_results:
            filename = Path(result['file']).name
            big5_str = ", ".join([f"{trait[0].upper()}:{score}" for trait, score in result['big5_final_scores'].items()])
            md_content += f"- **{filename}** - Big5: {big5_str} - MBTI: {result['mbti_type']}\n"

        if failed_results:
            md_content += "\n## å¤±è´¥çš„æ–‡ä»¶\n\n"
            for result in failed_results:
                filename = Path(result['file']).name
                md_content += f"- **{filename}** - é”™è¯¯: {result.get('error', 'Unknown error')}\n"

        # ä¿å­˜MarkdownæŠ¥å‘Š
        md_summary = output_dir / f"batch_report_{self.model}.md"
        with open(md_summary, 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"\nğŸ“Š æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"   JSON: {json_summary}")
        print(f"   Markdown: {md_summary}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡äº‘è¯„ä¼°å™¨åˆ†æ®µå¼Big5åˆ†æ')
    parser.add_argument('input_path', help='è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--model', default='qwen-long', choices=['qwen-long', 'qwen-max'],
                       help='ä½¿ç”¨çš„äº‘æ¨¡å‹')
    parser.add_argument('--output', default='batch_cloud_segmented_results', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--sample', type=int, help='é‡‡æ ·æ–‡ä»¶æ•°é‡')
    parser.add_argument('--filter', help='æ–‡ä»¶åè¿‡æ»¤æ¨¡å¼')
    parser.add_argument('--workers', type=int, default=2, help='å¹¶å‘å·¥ä½œæ•°')

    args = parser.parse_args()

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_path = Path(args.input_path)
    if input_path.is_file():
        input_files = [input_path]
    elif input_path.is_dir():
        input_files = list(input_path.glob("*.json"))
    else:
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return

    # åº”ç”¨è¿‡æ»¤å™¨
    if args.filter:
        input_files = [f for f in input_files if args.filter.lower() in f.name.lower()]

    # é‡‡æ ·
    if args.sample:
        input_files = input_files[:args.sample]

    if not input_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶")
        return

    print(f"ğŸ” æ‰¾åˆ° {len(input_files)} ä¸ªæ–‡ä»¶è¿›è¡Œåˆ†æ")

    # åˆ›å»ºæ‰¹é‡åˆ†æå™¨
    analyzer = BatchCloudSegmentedAnalyzer(
        model=args.model,
        max_workers=args.workers
    )

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output) / args.model
    output_dir.mkdir(parents=True, exist_ok=True)

    # æ‰§è¡Œæ‰¹é‡åˆ†æ
    def progress_callback(completed, total, result):
        print(f"ğŸ“ˆ è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)")

    results = analyzer.analyze_batch(input_files, output_dir, progress_callback)

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print(f"\nğŸ“‹ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
    analyzer.generate_summary_report(results, output_dir)

    # æœ€ç»ˆç»Ÿè®¡
    successful = sum(1 for r in results if r['success'])
    print(f"\nğŸ‰ æ‰¹é‡åˆ†æå®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()