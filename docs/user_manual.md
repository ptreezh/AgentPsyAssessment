# Portable PsyAgent ç”¨æˆ·æ‰‹å†Œ

## ç›®å½•
1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
3. [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
4. [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)
5. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
6. [è¯¦ç»†ä½¿ç”¨è¯´æ˜](#è¯¦ç»†ä½¿ç”¨è¯´æ˜)
7. [æµ‹è¯„æ¨¡å—](#æµ‹è¯„æ¨¡å—)
8. [åˆ†æè¯„ä¼°æ¨¡å—](#åˆ†æè¯„ä¼°æ¨¡å—)
9. [å‹åŠ›æµ‹è¯•æ¨¡å—](#å‹åŠ›æµ‹è¯•æ¨¡å—)
10. [é…ç½®æ–‡ä»¶è¯´æ˜](#é…ç½®æ–‡ä»¶è¯´æ˜)
11. [æ‰¹é‡å¤„ç†](#æ‰¹é‡å¤„ç†)
12. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
13. [APIå‚è€ƒ](#apiå‚è€ƒ)
14. [è®¸å¯è¯](#è®¸å¯è¯)

## é¡¹ç›®æ¦‚è¿°

Portable PsyAgent æ˜¯ä¸€ä¸ªä¾¿æºå¼å¿ƒç†è¯„ä¼°ä»£ç†ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§å¤§æ¨¡å‹è¯„ä¼°å™¨å’Œæœ¬åœ°Ollamaæ¨¡å‹ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå¯¹AIä»£ç†è¿›è¡Œå¤šç»´åº¦äººæ ¼æµ‹è¯„ï¼Œç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼Œå¹¶æ”¯æŒå®šå‘åŠ å¼ºå‹åŠ›æµ‹è¯•ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ§  **å¤šç»´åº¦äººæ ¼è¯„ä¼°** - æ”¯æŒBig Fiveäººæ ¼ç‰¹è´¨åˆ†æ
- ğŸ¤– **å¤šè¯„ä¼°å™¨æ”¯æŒ** - æ”¯æŒOpenAIã€Claudeã€Geminiã€DeepSeekã€GLMã€Qwenå’Œæœ¬åœ°Ollama
- ğŸ”§ **é…ç½®é©±åŠ¨** - é€šè¿‡é…ç½®æ–‡ä»¶è½»æ¾åˆ‡æ¢æ¨¡å‹å’Œå‚æ•°
- ğŸ“Š **è¯¦ç»†åˆ†ææŠ¥å‘Š** - ç”ŸæˆåŒ…å«åŠ¨æœºåˆ†æã€äººæ ¼ç‰¹è´¨å’Œè¡Œä¸ºæ¨¡å¼çš„ç»¼åˆæŠ¥å‘Š
- ğŸ›¡ï¸ **æœ¬åœ°è¯„ä¼°** - æ”¯æŒå®Œå…¨æœ¬åœ°åŒ–çš„Ollamaæ¨¡å‹è¯„ä¼°
- ğŸ” **è°ƒè¯•æ—¥å¿—** - å®Œæ•´çš„å¯¹è¯æ—¥å¿—å’Œè°ƒè¯•ä¿¡æ¯
- ğŸš€ **æ‰¹é‡åˆ†æ** - è‡ªåŠ¨å¤„ç†å¤§é‡æµ‹è¯„æŠ¥å‘Šï¼Œæ”¯æŒæ™ºèƒ½æ‰¹å¤„ç†å’Œè¿›åº¦è·Ÿè¸ª
- ğŸ’ª **å‹åŠ›æµ‹è¯•** - æ”¯æŒæƒ…æ„Ÿå‹åŠ›ã€è®¤çŸ¥é™·é˜±å’Œä¸Šä¸‹æ–‡è´Ÿè½½ç­‰å¤šç§å‹åŠ›æµ‹è¯•

## ç³»ç»Ÿè¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- Windowsã€Linux æˆ– macOS æ“ä½œç³»ç»Ÿ
- è‡³å°‘ 4GB RAMï¼ˆæ¨è 8GB æˆ–æ›´é«˜ï¼‰
- ç¡¬ç›˜ç©ºé—´ï¼šè‡³å°‘ 10GB å¯ç”¨ç©ºé—´

## å®‰è£…æŒ‡å—

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository_url>
cd portable_psyagent
```

### 2. å®‰è£…ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å¯é€‰ï¼šå®‰è£…Google Geminiæ”¯æŒ
pip install google-generativeai
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º`.env`æ–‡ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
# OpenAI
OPENAI_API_KEY=your_openai_key

# Anthropic Claude  
ANTHROPIC_API_KEY=your_claude_key

# Google Gemini
GOOGLE_API_KEY=your_gemini_key

# é˜¿é‡Œäº‘Qwen
DASHSCOPE_API_KEY=your_qwen_key

# DeepSeek
DEEPSEEK_API_KEY=your_deepseek_key

# GLM
GLM_API_KEY=your_glm_key
```

## å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹ï¼ˆæ¨èï¼‰

#### å®‰è£…Ollama

```bash
# Windows
# ä» https://ollama.ai/download ä¸‹è½½å®‰è£…

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# macOS
brew install ollama
```

#### ä¸‹è½½æ¨¡å‹

```bash
# å¯åŠ¨OllamaæœåŠ¡
ollama serve

# ä¸‹è½½æ¨èæ¨¡å‹
ollama pull llama3:latest
ollama pull qwen3:8b
ollama pull mistral-nemo:latest
```

### åŸºç¡€è¯„ä¼°

```bash
# ä½¿ç”¨é»˜è®¤è¯„ä¼°å™¨
python shared_analysis/analyze_results.py data/your_data.json

# ä½¿ç”¨ç‰¹å®šè¯„ä¼°å™¨
python shared_analysis/analyze_results.py data/your_data.json --evaluators gpt claude

# ä½¿ç”¨æœ¬åœ°Ollamaè¯„ä¼°å™¨
python shared_analysis/analyze_results.py data/your_data.json --evaluators ollama_llama3 ollama_qwen3
```

## è¯¦ç»†ä½¿ç”¨è¯´æ˜

### é¡¹ç›®ç»“æ„

```
portable_psyagent/
â”œâ”€â”€ llm_assessment/          # æµ‹è¯„æ¨¡å—
â”‚   â”œâ”€â”€ run_assessment_unified.py  # ç»Ÿä¸€æµ‹è¯„å…¥å£
â”‚   â”œâ”€â”€ roles/               # è§’è‰²å®šä¹‰æ–‡ä»¶
â”‚   â”œâ”€â”€ test_files/          # æµ‹è¯•é¢˜åº“
â”‚   â”œâ”€â”€ results/             # æµ‹è¯„ç»“æœ
â”‚   â””â”€â”€ services/            # æ ¸å¿ƒæœåŠ¡
â”œâ”€â”€ shared_analysis/         # åˆ†æè¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ analyze_results.py   # ç»“æœåˆ†æä¸»ç¨‹åº
â”‚   â”œâ”€â”€ analyze_big5_results.py  # Big Fiveåˆ†æ
â”‚   â”œâ”€â”€ analyze_motivation.py    # åŠ¨æœºåˆ†æ
â”‚   â””â”€â”€ ollama_evaluator.py  # Ollamaè¯„ä¼°å™¨
â”œâ”€â”€ interference_materials/  # å¹²æ‰°ææ–™ï¼ˆå‹åŠ›æµ‹è¯•ï¼‰
â”œâ”€â”€ config/                  # é…ç½®æ–‡ä»¶
â”œâ”€â”€ batch_analysis_output/   # æ‰¹é‡åˆ†æè¾“å‡º
â””â”€â”€ docs/                    # æ–‡æ¡£
```

## æµ‹è¯„æ¨¡å—

### è¿è¡Œæµ‹è¯„

```bash
# åŸºç¡€æµ‹è¯„
python llm_assessment/run_assessment_unified.py --model_name gemma3:latest --test_file big5 --role_name a1

# å¸¦å‹åŠ›æµ‹è¯•çš„æµ‹è¯„
python llm_assessment/run_assessment_unified.py --model_name gemma3:latest --test_file big5 --role_name a1 --emotional-stress-level 3 --cognitive-trap-type p

# è®¾ç½®æ¸©åº¦å‚æ•°
python llm_assessment/run_assessment_unified.py --model_name gemma3:latest --test_file big5 --role_name a1 --tmpr 0.7

# è®¾ç½®ä¸Šä¸‹æ–‡é•¿åº¦
python llm_assessment/run_assessment_unified.py --model_name gemma3:latest --test_file big5 --role_name a1 --context-length-mode static --context-length-static 4
```

### æµ‹è¯„å‚æ•°è¯´æ˜

- `--model_name`: æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆå¦‚ ollama/gemma3:latestï¼‰
- `--test_file`: æµ‹è¯•æ–‡ä»¶åæˆ–è·¯å¾„
- `--role_name`: è§’è‰²åç§°
- `--emotional-stress-level`: æƒ…æ„Ÿå‹åŠ›ç­‰çº§ï¼ˆ0-4ï¼‰
- `--cognitive-trap-type`: è®¤çŸ¥é™·é˜±ç±»å‹ï¼ˆp, c, s, rï¼‰
- `--tmpr`: æ¨¡å‹æ¸©åº¦è®¾ç½®
- `--context-length-mode`: ä¸Šä¸‹æ–‡é•¿åº¦æ¨¡å¼ï¼ˆauto, static, dynamic, noneï¼‰
- `--timeout`: æ¨¡å‹å“åº”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

## åˆ†æè¯„ä¼°æ¨¡å—

### åŠ¨æœºåˆ†æ

```bash
# è¿è¡ŒåŠ¨æœºåˆ†æï¼ˆæ— éœ€APIï¼‰
python shared_analysis/analyze_motivation.py data/your_data.json --debug
```

### Big Fiveäººæ ¼åˆ†æ

```bash
# Big FiveåŸºç¡€åˆ†æ
python shared_analysis/analyze_big5_results.py data/your_data.json
```

### ç»¼åˆåˆ†æ

```bash
# ä½¿ç”¨é»˜è®¤è¯„ä¼°å™¨
python shared_analysis/analyze_results.py data/your_data.json

# ä½¿ç”¨ç‰¹å®šè¯„ä¼°å™¨
python shared_analysis/analyze_results.py data/your_data.json --evaluators gpt claude

# ä½¿ç”¨æœ¬åœ°Ollamaè¯„ä¼°å™¨
python shared_analysis/analyze_results.py data/your_data.json --evaluators ollama_llama3 ollama_qwen3
```

## å‹åŠ›æµ‹è¯•æ¨¡å—

### æ”¯æŒçš„å‹åŠ›æµ‹è¯•ç±»å‹

1. **æƒ…æ„Ÿå‹åŠ›æµ‹è¯•** - é€šè¿‡ä¸åŒç­‰çº§çš„æƒ…æ„Ÿå‹åŠ›å½±å“æ¨¡å‹è¡¨ç°
2. **è®¤çŸ¥é™·é˜±æµ‹è¯•** - å¼•å…¥æ‚–è®ºã€å¾ªç¯æ€§ã€è¯­ä¹‰è°¬è¯¯å’Œç¨‹åºæ€§é™·é˜±
3. **ä¸Šä¸‹æ–‡è´Ÿè½½æµ‹è¯•** - é€šè¿‡å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æµ‹è¯•æ¨¡å‹å¤„ç†èƒ½åŠ›

### å‹åŠ›æµ‹è¯•å‚æ•°

- `-esL, --emotional-stress-level`: æƒ…æ„Ÿå‹åŠ›ç­‰çº§ï¼ˆ0-4ï¼‰
- `-ct, --cognitive-trap-type`: è®¤çŸ¥é™·é˜±ç±»å‹
  - `p`: æ‚–è®ºé™·é˜±
  - `c`: å¾ªç¯æ€§é™·é˜±
  - `s`: è¯­ä¹‰è°¬è¯¯é™·é˜±
  - `r`: ç¨‹åºæ€§é™·é˜±
- `--context-length-mode`: ä¸Šä¸‹æ–‡é•¿åº¦æ¨¡å¼
  - `auto`: è‡ªåŠ¨æ£€æµ‹
  - `static`: å›ºå®šé•¿åº¦
  - `dynamic`: åŠ¨æ€æ¯”ä¾‹
  - `none`: ç¦ç”¨ä¸Šä¸‹æ–‡æ³¨å…¥

## é…ç½®æ–‡ä»¶è¯´æ˜

### Ollamaé…ç½® (`config/ollama_config.json`)

```json
{
  "ollama": {
    "base_url": "http://localhost:11434",
    "timeout": 120,
    "models": {
      "llama3": {
        "name": "llama3:latest",
        "temperature": 0.1,
        "max_tokens": 1024,
        "description": "Meta Llama 3 - é€šç”¨å¤§æ¨¡å‹"
      },
      "qwen3": {
        "name": "qwen3:8b",
        "temperature": 0.1,
        "max_tokens": 1024,
        "description": "é˜¿é‡Œäº‘é€šä¹‰åƒé—®3 - 8Bå‚æ•°ç‰ˆæœ¬"
      },
      "mistral": {
        "name": "mistral-nemo:latest",
        "temperature": 0.1,
        "max_tokens": 1024,
        "description": "Mistral NeMo - é«˜æ€§èƒ½æ¨ç†æ¨¡å‹"
      }
    }
  },
  "evaluators": {
    "ollama_llama3": {
      "provider": "ollama",
      "model": "llama3",
      "description": "Llama3 æœ¬åœ°è¯„ä¼°å™¨"
    },
    "ollama_qwen3": {
      "provider": "ollama",
      "model": "qwen3",
      "description": "Qwen3 æœ¬åœ°è¯„ä¼°å™¨"
    },
    "ollama_mistral": {
      "provider": "ollama",
      "model": "mistral",
      "description": "Mistral NeMo æœ¬åœ°è¯„ä¼°å™¨"
    }
  }
}
```

## æ‰¹é‡å¤„ç†

### æ‰¹é‡åˆ†æ

```bash
# æŸ¥çœ‹æ–‡ä»¶ç»Ÿè®¡
python ultimate_batch_analysis.py --stats

# å¿«é€Ÿæµ‹è¯• (5ä¸ªæ–‡ä»¶)
python ultimate_batch_analysis.py --quick

# åˆ†æç‰¹å®šæ¨¡å‹ (å¦‚deepseek)
python ultimate_batch_analysis.py --filter deepseek

# å®Œæ•´æ‰¹é‡åˆ†æ (æ‰€æœ‰294ä¸ªæ–‡ä»¶)
python ultimate_batch_analysis.py

# Windowsç”¨æˆ·ä¸€é”®å¯åŠ¨
start_batch_analysis.bat
```

### æ”¯æŒçš„æµ‹è¯„æ•°æ®

ç³»ç»Ÿæ”¯æŒè‡ªåŠ¨åˆ†æ `results/results` ç›®å½•ä¸­çš„æµ‹è¯„æŠ¥å‘Šï¼ŒåŒ…å«å¤šä¸ªæ¨¡å‹ç³»åˆ—çš„æµ‹è¯•æ•°æ®ã€‚

### æ‰¹é‡åˆ†æç‰¹æ€§

- ğŸ”„ **è‡ªåŠ¨æ ¼å¼è½¬æ¢** - æ”¯æŒåŸå§‹æµ‹è¯„æ•°æ®æ ¼å¼
- ğŸ“Š **æ™ºèƒ½æ‰¹å¤„ç†** - æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé”™è¯¯æ¢å¤
- â±ï¸ **è¿›åº¦è·Ÿè¸ª** - å®æ—¶æ˜¾ç¤ºåˆ†æè¿›åº¦å’Œé¢„è®¡æ—¶é—´
- ğŸ“‹ **è¯¦ç»†æŠ¥å‘Š** - ç”ŸæˆJSONå’ŒMarkdownæ ¼å¼æ‘˜è¦
- ğŸ¯ **çµæ´»è¿‡æ»¤** - æŒ‰æ¨¡å‹ã€æ ·æœ¬æ•°é‡ç­‰æ¡ä»¶è¿‡æ»¤

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Ollamaè¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥OllamaæœåŠ¡
   ollama ps
   curl http://localhost:11434/api/tags
   ```

2. **æ‰¹é‡åˆ†æä¸­æ–­**
   ```bash
   # æ£€æŸ¥è¾“å‡ºç›®å½•
   ls -la batch_analysis_results/
   
   # é‡æ–°è¿è¡Œï¼ˆä¼šè‡ªåŠ¨è·³è¿‡å·²å®Œæˆçš„æ–‡ä»¶ï¼‰
   python ultimate_batch_analysis.py --filter deepseek
   ```

3. **å†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹é‡å¤§å°
   python ultimate_batch_analysis.py --sample 10
   ```

4. **APIå¯†é’¥é—®é¢˜**
   ```bash
   # æ£€æŸ¥ç¯å¢ƒå˜é‡
   echo $OPENAI_API_KEY
   ```

5. **æ¨¡å—ç¼ºå¤±**
   ```bash
   # å®‰è£…ç¼ºå¤±çš„ä¾èµ–
   pip install google-generativeai
   ```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†è°ƒè¯•è¾“å‡º
python shared_analysis/analyze_results.py data.json --evaluators ollama_llama3
```

æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š
- `logs/evaluator_conversation_log.txt` - å¯¹è¯è®°å½•
- `logs/debug_info.json` - è°ƒè¯•ä¿¡æ¯

## APIå‚è€ƒ

### æµ‹è¯„API

#### run_assessment_unified.py

ä¸»è¦å‚æ•°ï¼š
- `--model_name` (å¿…éœ€): æ¨¡å‹æ ‡è¯†ç¬¦
- `--test_file` (å¿…éœ€): æµ‹è¯•æ–‡ä»¶
- `--role_name`: è§’è‰²åç§°
- `--debug`: å¯ç”¨è°ƒè¯•æ¨¡å¼
- `--test_connection`: ä»…æµ‹è¯•æ¨¡å‹è¿æ¥æ€§

å‹åŠ›æµ‹è¯•å‚æ•°ï¼š
- `--emotional-stress-level`: æƒ…æ„Ÿå‹åŠ›ç­‰çº§ (0-4)
- `--cognitive-trap-type`: è®¤çŸ¥é™·é˜±ç±»å‹ (p, c, s, r)
- `--tmpr`: æ¨¡å‹æ¸©åº¦è®¾ç½®
- `--context-length-mode`: ä¸Šä¸‹æ–‡é•¿åº¦æ¨¡å¼
- `--timeout`: å“åº”è¶…æ—¶æ—¶é—´

### åˆ†æAPI

#### analyze_results.py

ä¸»è¦åŠŸèƒ½ï¼š
- å¯¹æµ‹è¯„ç»“æœè¿›è¡Œç»¼åˆåˆ†æ
- ç”ŸæˆBig Fiveå’ŒMBTIäººæ ¼è¯„ä¼°
- æ”¯æŒå¤šç§è¯„ä¼°å™¨

#### analyze_motivation.py

ä¸»è¦åŠŸèƒ½ï¼š
- å¯¹æµ‹è¯„ç»“æœè¿›è¡ŒåŠ¨æœºåˆ†æ
- ç”ŸæˆåŠ¨æœºæµ‹è¯•æŠ¥å‘Š
- æ”¯æŒMarkdownæ ¼å¼è¾“å‡º

#### analyze_big5_results.py

ä¸»è¦åŠŸèƒ½ï¼š
- ä¸“é—¨é’ˆå¯¹Big Fiveäººæ ¼ç‰¹è´¨è¿›è¡Œåˆ†æ
- ç”Ÿæˆè¯¦ç»†çš„Big Fiveè¯„åˆ†æŠ¥å‘Š

## è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ç”¨äºç ”ç©¶å’Œæ•™è‚²ç›®çš„ã€‚