#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´50é¢˜è¯„ä¼°è„šæœ¬ - ä½¿ç”¨1-3-5è¯„åˆ†æ ‡å‡†
"""

import json
import sys
import os
import time

def run_complete_assessment():
    """è¿è¡Œå®Œæ•´çš„50é¢˜è¯„ä¼°"""
    print("=" * 60)
    print("å¼€å§‹æ‰§è¡Œå®Œæ•´çš„50é¢˜äººæ ¼è¯„ä¼°")
    print("è¯„åˆ†æ ‡å‡†: ä¸¥æ ¼éµå¾ª1-3-5ä¸‰æ¡£è¯„åˆ†")
    print("=" * 60)
    print("å¼€å§‹æ—¶é—´: " + time.strftime('%Y-%m-%d %H:%M:%S'))
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡è§£å†³Windowsç¼–ç é—®é¢˜
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        sys.path.append('batchAnalysizeTools')
        from batch_segmented_analysis import BatchSegmentedPersonalityAnalyzer
        
        # åŠ è½½è¯„ä¼°æ•°æ®
        print("\n1. åŠ è½½è¯„ä¼°æ–‡ä»¶...")
        with open("results/results/asses_deepseek_r1_70b_agent_big_five_50_complete2_def_e0_t0_0_09091.json", 'r', encoding='utf-8') as f:
            assessment_data = json.load(f)
        print("   âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # åˆå§‹åŒ–åˆ†æå™¨
        print("\n2. åˆå§‹åŒ–åˆ†æå™¨...")
        analyzer = BatchSegmentedPersonalityAnalyzer(
            max_questions_per_segment=2,  # æ¯æ®µ2ä¸ªé—®é¢˜
            evaluator_name="gemma3",
            base_url="http://localhost:11434"
        )
        print("   âœ“ åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æå–é—®é¢˜
        print("\n3. æå–é—®é¢˜...")
        questions = analyzer.extract_questions(assessment_data)
        print("   âœ“ æˆåŠŸæå– " + str(len(questions)) + " ä¸ªé—®é¢˜")
        
        # åˆ›å»ºåˆ†æ®µ
        print("\n4. åˆ›å»ºåˆ†æ®µ...")
        segments = analyzer.create_segments(questions)
        print("   âœ“ æˆåŠŸåˆ›å»º " + str(len(segments)) + " ä¸ªåˆ†æ®µ")
        
        # åˆ†ææ‰€æœ‰åˆ†æ®µ
        print("\n5. å¼€å§‹åˆ†ææ‰€æœ‰åˆ†æ®µ...")
        successful_segments = 0
        total_questions_analyzed = 0
        
        for i in range(len(segments)):
            segment = segments[i]
            print("   åˆ†æç¬¬ " + str(i+1) + "/" + str(len(segments)) + " ä¸ªåˆ†æ®µ (" + str(len(segment)) + " ä¸ªé—®é¢˜)..."))
            try:
                segment_analysis = analyzer.analyze_segment(segment, i+1)
                if 'llm_response' in segment_analysis:
                    analyzer.accumulate_scores(segment_analysis['llm_response'])
                    successful_segments += 1
                    total_questions_analyzed += len(segment)
                    print("     âœ“ åˆ†æ®µ " + str(i+1) + " åˆ†æå®Œæˆ")
                else:
                    print("     âœ— åˆ†æ®µ " + str(i+1) + " åˆ†æå¤±è´¥")
            except Exception as e:
                print("     âœ— åˆ†æ®µ " + str(i+1) + " åˆ†æå‡ºé”™: " + str(e))
                continue
        
        print("\n   âœ“ æˆåŠŸåˆ†æ " + str(successful_segments) + "/" + str(len(segments)) + " ä¸ªåˆ†æ®µ")
        print("   âœ“ æ€»å…±åˆ†æ " + str(total_questions_analyzed) + " ä¸ªé—®é¢˜")
        
        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        print("\n6. è®¡ç®—æœ€ç»ˆåˆ†æ•°...")
        final_scores = analyzer.calculate_final_scores()
        print("   âœ“ æœ€ç»ˆåˆ†æ•°è®¡ç®—æˆåŠŸ")
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\n7. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š...")
        generate_complete_report(final_scores)
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        print("\n" + "=" * 60)
        print("å®Œæ•´50é¢˜è¯„ä¼°æ‰§è¡Œå®Œæˆ!")
        print("ç»“æŸæ—¶é—´: " + time.strftime('%Y-%m-%d %H:%M:%S'))
        print("æ€»è€—æ—¶: " + str(round(elapsed_time, 2)) + " ç§’ (" + str(round(elapsed_time/60, 2)) + " åˆ†é’Ÿ)")
        print("=" * 60)
        
    except Exception as e:
        print("\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: " + str(e))
        import traceback
        traceback.print_exc()

def generate_complete_report(final_scores):
    """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
    # Big Five åˆ†æ•°
    print("\nã€Big Five äººæ ¼ç»´åº¦è¯„åˆ†ã€‘")
    print("-" * 50)
    big_five_scores = final_scores['big_five']
    
    traits = [
        ('openness_to_experience', 'å¼€æ”¾æ€§'),
        ('conscientiousness', 'å°½è´£æ€§'),
        ('extraversion', 'å¤–å‘æ€§'),
        ('agreeableness', 'å®œäººæ€§'),
        ('neuroticism', 'ç¥ç»è´¨')
    ]
    
    for trait_key, trait_name in traits:
        score = big_five_scores[trait_key]['score']
        weight = big_five_scores[trait_key]['weight']
        print(f"{trait_name:8} : {score:5.1f}/10.0 (åŸºäº {weight:2d} ä¸ªé—®é¢˜)")
    
    # MBTI ç±»å‹
    print("\nã€MBTI äººæ ¼ç±»å‹ã€‘")
    print("-" * 50)
    mbti = final_scores['mbti']
    print(f"ç±»å‹: {mbti['type']}")
    print(f"ç½®ä¿¡åº¦: {mbti['confidence']:.2f}")
    
    # Belbin å›¢é˜Ÿè§’è‰²
    print("\nã€Belbin å›¢é˜Ÿè§’è‰²ã€‘")
    print("-" * 50)
    belbin = final_scores['belbin']
    print(f"ä¸»è¦è§’è‰²: {belbin['primary_role']}")
    print(f"æ¬¡è¦è§’è‰²: {belbin['secondary_role']}")
    
    # ä¿å­˜å®Œæ•´æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_data = {
        'summary': {
            'big_five': big_five_scores,
            'mbti': mbti,
            'belbin': belbin,
            'total_questions_analyzed': len(final_scores['per_question_scores'])
        },
        'per_question_scores': final_scores['per_question_scores'],
        'analysis_summary': final_scores['analysis_summary']
    }
    
    # ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
    with open('batchAnalysizeTools/complete_assessment_report.json', 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    print("\nğŸ“„ JSONæ ¼å¼å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: batchAnalysizeTools/complete_assessment_report.json")
    
    # ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š
    generate_markdown_report(report_data)
    print("ğŸ“ Markdownæ ¼å¼å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: batchAnalysizeTools/complete_assessment_report.md")
    
    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    generate_summary_report(report_data)
    print("ğŸ“‹ æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: batchAnalysizeTools/assessment_summary.txt")

def generate_markdown_report(report_data):
    """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
    md_content = "# å®Œæ•´50é¢˜äººæ ¼æµ‹è¯„æŠ¥å‘Š\n\n"
    md_content += "## æ¦‚è¿°\n\n"
    md_content += "æœ¬æŠ¥å‘ŠåŸºäº50ä¸ªé—®é¢˜çš„å®Œæ•´äººæ ¼æµ‹è¯„ï¼Œä½¿ç”¨Gemma3æ¨¡å‹è¿›è¡Œåˆ†æï¼Œä¸¥æ ¼éµå¾ª1-3-5ä¸‰æ¡£è¯„åˆ†æ ‡å‡†ã€‚\n\n"
    
    md_content += "## Big Five äººæ ¼ç»´åº¦è¯„åˆ†\n\n"
    md_content += "| ç»´åº¦ | åˆ†æ•° | é—®é¢˜æ•°é‡ |\n"
    md_content += "|------|------|----------|\n"
    
    big_five = report_data['summary']['big_five']
    traits = [
        ('openness_to_experience', 'å¼€æ”¾æ€§'),
        ('conscientiousness', 'å°½è´£æ€§'),
        ('extraversion', 'å¤–å‘æ€§'),
        ('agreeableness', 'å®œäººæ€§'),
        ('neuroticism', 'ç¥ç»è´¨')
    ]
    
    for trait_key, trait_name in traits:
        score = big_five[trait_key]['score']
        weight = big_five[trait_key]['weight']
        md_content += f"| {trait_name} | {score:.1f}/10.0 | {weight} |\n"
    
    md_content += f"\n## MBTI äººæ ¼ç±»å‹\n\n"
    md_content += f"- ç±»å‹: {report_data['summary']['mbti']['type']}\n"
    md_content += f"- ç½®ä¿¡åº¦: {report_data['summary']['mbti']['confidence']:.2f}\n\n"
    
    md_content += f"## Belbin å›¢é˜Ÿè§’è‰²\n\n"
    md_content += f"- ä¸»è¦è§’è‰²: {report_data['summary']['belbin']['primary_role']}\n"
    md_content += f"- æ¬¡è¦è§’è‰²: {report_data['summary']['belbin']['secondary_role']}\n\n"
    
    md_content += "## é—®é¢˜çº§åˆ«è¯¦ç»†è¯„åˆ†\n\n"
    md_content += "ä»¥ä¸‹ä¸ºæ‰€æœ‰é—®é¢˜çš„è¯¦ç»†è¯„åˆ†ï¼ˆä¸¥æ ¼éµå¾ª1-3-5è¯„åˆ†æ ‡å‡†ï¼‰:\n"
    
    for i in range(len(report_data['per_question_scores'])):
        score = report_data['per_question_scores'][i]
        md_content += f"\n### é—®é¢˜ {i+1}: {score['dimension']}\n\n"
        md_content += f"- é—®é¢˜ID: {score['question_id']}\n"
        md_content += "- Big Five è¯„åˆ†:\n"
        
        for trait, trait_score in score['big_five_scores'].items():
            # ç¡®ä¿è¯„åˆ†æ˜¯1, 3, æˆ–5
            fixed_score = trait_score['score']
            if fixed_score not in [1, 3, 5]:
                # å°†è¯„åˆ†æ˜ å°„åˆ°æœ€è¿‘çš„1-3-5å€¼
                if fixed_score < 2:
                    fixed_score = 1
                elif fixed_score < 4:
                    fixed_score = 3
                else:
                    fixed_score = 5
            md_content += f"  - {trait}: {fixed_score} ({trait_score['evidence']})\n"
    
    with open('batchAnalysizeTools/complete_assessment_report.md', 'w', encoding='utf-8') as f:
        f.write(md_content)

def generate_summary_report(report_data):
    """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
    summary_content = "å®Œæ•´50é¢˜äººæ ¼æµ‹è¯„æ‘˜è¦æŠ¥å‘Š\n"
    summary_content += "=" * 40 + "\n\n"
    
    summary_content += "Big Five äººæ ¼ç»´åº¦è¯„åˆ†:\n"
    summary_content += "-" * 30 + "\n"
    big_five = report_data['summary']['big_five']
    traits = [
        ('openness_to_experience', 'å¼€æ”¾æ€§'),
        ('conscientiousness', 'å°½è´£æ€§'),
        ('extraversion', 'å¤–å‘æ€§'),
        ('agreeableness', 'å®œäººæ€§'),
        ('neuroticism', 'ç¥ç»è´¨')
    ]
    
    for trait_key, trait_name in traits:
        score = big_five[trait_key]['score']
        summary_content += f"{trait_name}: {score:.1f}/10.0\n"
    
    summary_content += f"\nMBTI äººæ ¼ç±»å‹: {report_data['summary']['mbti']['type']}\n"
    summary_content += f"ç½®ä¿¡åº¦: {report_data['summary']['mbti']['confidence']:.2f}\n\n"
    
    summary_content += f"Belbin å›¢é˜Ÿè§’è‰²:\n"
    summary_content += f"ä¸»è¦è§’è‰²: {report_data['summary']['belbin']['primary_role']}\n"
    summary_content += f"æ¬¡è¦è§’è‰²: {report_data['summary']['belbin']['secondary_role']}\n"
    
    with open('batchAnalysizeTools/assessment_summary.txt', 'w', encoding='utf-8') as f:
        f.write(summary_content)

if __name__ == "__main__":
    run_complete_assessment()