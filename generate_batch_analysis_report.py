#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ - åˆ†æè™šå‡å…±è¯†é£é™©å’Œå¯ä¿¡åº¦åˆ†å¸ƒ
"""

import json
import os
import glob
from datetime import datetime
from pathlib import Path
from collections import defaultdict, Counter
import statistics

class BatchCredibilityAnalyzer:
    def __init__(self):
        self.olllama_results = []
        self.cloud_results = []
        self.credibility_stats = {
            'ollama': {'scores': [], 'success_rates': [], 'mbti_types': []},
            'cloud': {'scores': [], 'success_rates': [], 'mbti_types': []}
        }

    def load_results(self, ollama_dir="three_model_consistency_results",
                     cloud_dir="cloud_segment_results"):
        """åŠ è½½ä¸¤ä¸ªè¯„ä¼°å™¨çš„ç»“æœ"""

        # åŠ è½½Ollamaè¯„ä¼°å™¨ç»“æœ
        ollama_files = glob.glob(f"{ollama_dir}/*.json")
        print(f"ğŸ“‚ æ‰¾åˆ° {len(ollama_files)} ä¸ªOllamaè¯„ä¼°ç»“æœæ–‡ä»¶")

        for file_path in ollama_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    data['source_file'] = os.path.basename(file_path)
                    self.olllama_results.append(data)

                    # æ”¶é›†ç»Ÿè®¡æ•°æ®
                    if 'consistency_analysis' in data:
                        consistency = data['consistency_analysis']
                        if 'confidence_score' in consistency:
                            self.credibility_stats['ollama']['scores'].append(consistency['confidence_score'])
                        if 'overall_confidence' in consistency:
                            self.credibility_stats['ollama']['success_rates'].append(consistency['overall_confidence'])
                        if 'consensus_mbti' in consistency:
                            self.credibility_stats['ollama']['mbti_types'].append(consistency['consensus_mbti'])

            except Exception as e:
                print(f"âŒ åŠ è½½Ollamaæ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        # åŠ è½½äº‘æ¨¡å‹è¯„ä¼°å™¨ç»“æœ
        cloud_files = glob.glob(f"{cloud_dir}/*.json")
        print(f"ğŸ“‚ æ‰¾åˆ° {len(cloud_files)} ä¸ªäº‘æ¨¡å‹è¯„ä¼°ç»“æœæ–‡ä»¶")

        for file_path in cloud_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    data['source_file'] = os.path.basename(file_path)
                    self.cloud_results.append(data)

                    # æ”¶é›†ç»Ÿè®¡æ•°æ®
                    if 'avg_models_per_segment' in data:
                        success_rate = data['avg_models_per_segment'] / 3.0  # æ ‡å‡†åŒ–åˆ°0-1
                        self.credibility_stats['cloud']['success_rates'].append(success_rate)

                    # ä¼°ç®—å¯ä¿¡åº¦åˆ†æ•°ï¼ˆåŸºäºæˆåŠŸç‡å’Œå¤‡ç”¨æ¨¡å‹ä½¿ç”¨æƒ…å†µï¼‰
                    backup_usage = data.get('backup_usage_rate', 0)
                    success_penalty = 1.0 - success_rate
                    estimated_credibility = max(0, min(100, (1 - success_penalty - backup_usage) * 100))
                    self.credibility_stats['cloud']['scores'].append(estimated_credibility)

                    if 'mbti_type' in data:
                        self.credibility_stats['cloud']['mbti_types'].append(data['mbti_type'])

            except Exception as e:
                print(f"âŒ åŠ è½½äº‘æ¨¡å‹æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    def analyze_false_consensus_risks(self):
        """åˆ†æè™šå‡å…±è¯†é£é™©"""
        print("\nğŸ” è™šå‡å…±è¯†é£é™©åˆ†æ")
        print("=" * 60)

        # åˆ†æOllamaè¯„ä¼°å™¨çš„å¤±è´¥æ¨¡å¼
        ollama_failures = 0
        ollama_low_success = 0
        ollama_total_segments = 0

        for result in self.olllama_results:
            if 'model_results' in result:
                for model, model_result in result['model_results'].items():
                    success_rate = model_result.get('success_rate', 0)
                    ollama_total_segments += 1
                    if success_rate < 0.5:  # æˆåŠŸç‡ä½äº50%
                        ollama_failures += 1
                    if success_rate < 0.8:  # æˆåŠŸç‡ä½äº80%
                        ollama_low_success += 1

        ollama_failure_rate = (ollama_failures / ollama_total_segments * 100) if ollama_total_segments > 0 else 0
        ollama_low_success_rate = (ollama_low_success / ollama_total_segments * 100) if ollama_total_segments > 0 else 0

        print(f"ğŸ¤– Ollamaè¯„ä¼°å™¨å¤±è´¥åˆ†æ:")
        print(f"   æ€»æ®µæ•°: {ollama_total_segments}")
        print(f"   ä¸¥é‡å¤±è´¥æ®µæ•° (<50%æˆåŠŸç‡): {ollama_failures} ({ollama_failure_rate:.1f}%)")
        print(f"   ä½æˆåŠŸç‡æ®µæ•° (<80%æˆåŠŸç‡): {ollama_low_success} ({ollama_low_success_rate:.1f}%)")

        # åˆ†æäº‘æ¨¡å‹è¯„ä¼°å™¨çš„å¤±è´¥æ¨¡å¼
        cloud_low_success = 0
        cloud_very_low_success = 0
        cloud_total = len(self.cloud_results)

        for result in self.cloud_results:
            avg_models = result.get('avg_models_per_segment', 0)
            success_rate = avg_models / 3.0  # æ ‡å‡†åŒ–

            if success_rate < 0.3:  # æˆåŠŸç‡ä½äº30%
                cloud_very_low_success += 1
            if success_rate < 0.7:  # æˆåŠŸç‡ä½äº70%
                cloud_low_success += 1

        cloud_very_low_rate = (cloud_very_low_success / cloud_total * 100) if cloud_total > 0 else 0
        cloud_low_rate = (cloud_low_success / cloud_total * 100) if cloud_total > 0 else 0

        print(f"\nâ˜ï¸ äº‘æ¨¡å‹è¯„ä¼°å™¨å¤±è´¥åˆ†æ:")
        print(f"   æ€»æ–‡ä»¶æ•°: {cloud_total}")
        print(f"   æä½æˆåŠŸç‡æ–‡ä»¶ (<30%): {cloud_very_low_success} ({cloud_very_low_rate:.1f}%)")
        print(f"   ä½æˆåŠŸç‡æ–‡ä»¶ (<70%): {cloud_low_success} ({cloud_low_rate:.1f}%)")

        # åˆ†æMBTIä¸€è‡´æ€§
        ollama_mbti_counter = Counter(self.credibility_stats['ollama']['mbti_types'])
        cloud_mbti_counter = Counter(self.credibility_stats['cloud']['mbti_types'])

        print(f"\nğŸ¯ MBTIç±»å‹åˆ†å¸ƒ:")
        print(f"   Ollamaè¯„ä¼°å™¨: {dict(ollama_mbti_counter.most_common(5))}")
        print(f"   äº‘æ¨¡å‹è¯„ä¼°å™¨: {dict(cloud_mbti_counter.most_common(5))}")

        return {
            'ollama_failure_rate': ollama_failure_rate,
            'ollama_low_success_rate': ollama_low_success_rate,
            'cloud_very_low_rate': cloud_very_low_rate,
            'cloud_low_rate': cloud_low_rate,
            'ollama_mbti_distribution': dict(ollama_mbti_counter),
            'cloud_mbti_distribution': dict(cloud_mbti_counter)
        }

    def analyze_credibility_distribution(self):
        """åˆ†æå¯ä¿¡åº¦åˆ†å¸ƒ"""
        print("\nğŸ“Š å¯ä¿¡åº¦åˆ†å¸ƒåˆ†æ")
        print("=" * 60)

        for evaluator, stats in self.credibility_stats.items():
            scores = stats['scores']
            if not scores:
                continue

            print(f"\nğŸ¤– {evaluator.upper()}è¯„ä¼°å™¨å¯ä¿¡åº¦ç»Ÿè®¡:")
            print(f"   æ ·æœ¬æ•°é‡: {len(scores)}")
            print(f"   å¹³å‡å¯ä¿¡åº¦: {statistics.mean(scores):.1f}")
            print(f"   ä¸­ä½æ•°å¯ä¿¡åº¦: {statistics.median(scores):.1f}")
            print(f"   æœ€ä½å¯ä¿¡åº¦: {min(scores):.1f}")
            print(f"   æœ€é«˜å¯ä¿¡åº¦: {max(scores):.1f}")

            # å¯ä¿¡åº¦åˆ†å¸ƒ
            high_credibility = sum(1 for s in scores if s >= 80)
            medium_credibility = sum(1 for s in scores if 60 <= s < 80)
            low_credibility = sum(1 for s in scores if s < 60)

            print(f"   é«˜å¯ä¿¡åº¦ (â‰¥80åˆ†): {high_credibility} ({high_credibility/len(scores)*100:.1f}%)")
            print(f"   ä¸­ç­‰å¯ä¿¡åº¦ (60-79åˆ†): {medium_credibility} ({medium_credibility/len(scores)*100:.1f}%)")
            print(f"   ä½å¯ä¿¡åº¦ (<60åˆ†): {low_credibility} ({low_credibility/len(scores)*100:.1f}%)")

    def cross_validator_analysis(self):
        """äº¤å‰éªŒè¯åˆ†æ"""
        print("\nğŸ”„ äº¤å‰éªŒè¯åˆ†æ")
        print("=" * 60)

        # æ‰¾åˆ°ç›¸åŒæ–‡ä»¶çš„Ollamaå’Œäº‘æ¨¡å‹ç»“æœ
        common_files = set()
        ollama_file_map = {}
        cloud_file_map = {}

        for result in self.olllama_results:
            base_name = result['source_file'].replace('_three_model_consistency_analysis.json', '')
            ollama_file_map[base_name] = result
            common_files.add(base_name)

        for result in self.cloud_results:
            base_name = result['source_file'].replace('_cloud_segment_analysis.json', '')
            cloud_file_map[base_name] = result
            common_files.intersection_update({base_name})

        print(f"ğŸ“‹ æ‰¾åˆ° {len(common_files)} ä¸ªå…±åŒè¯„ä¼°çš„æ–‡ä»¶")

        if len(common_files) > 0:
            # æ¯”è¾ƒMBTIä¸€è‡´æ€§
            mbti_matches = 0
            mbti_comparisons = []

            for file_name in common_files:
                ollama_result = ollama_file_map[file_name]
                cloud_result = cloud_file_map[file_name]

                ollama_mbti = ollama_result.get('consistency_analysis', {}).get('consensus_mbti', 'Unknown')
                cloud_mbti = cloud_result.get('mbti_type', 'Unknown')

                mbti_comparisons.append({
                    'file': file_name,
                    'ollama_mbti': ollama_mbti,
                    'cloud_mbti': cloud_mbti,
                    'match': ollama_mbti == cloud_mbti
                })

                if ollama_mbti == cloud_mbti:
                    mbti_matches += 1

            consistency_rate = (mbti_matches / len(common_files) * 100) if common_files else 0
            print(f"ğŸ¯ MBTIç±»å‹ä¸€è‡´æ€§: {mbti_matches}/{len(common_files)} ({consistency_rate:.1f}%)")

            # æ˜¾ç¤ºä¸ä¸€è‡´çš„æ¡ˆä¾‹
            inconsistent_cases = [comp for comp in mbti_comparisons if not comp['match']]
            if inconsistent_cases:
                print(f"\nâš ï¸ MBTIä¸ä¸€è‡´æ¡ˆä¾‹ (å‰10ä¸ª):")
                for i, case in enumerate(inconsistent_cases[:10]):
                    print(f"   {i+1}. {case['file'][:50]}...")
                    print(f"      Ollama: {case['ollama_mbti']} vs Cloud: {case['cloud_mbti']}")

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")

        report = {
            'generation_time': datetime.now().isoformat(),
            'analysis_summary': {
                'ollama_total_files': len(self.olllama_results),
                'cloud_total_files': len(self.cloud_results),
                'total_analyzed': len(self.olllama_results) + len(self.cloud_results)
            },
            'false_consensus_analysis': self.analyze_false_consensus_risks(),
            'credibility_distribution': {},
            'cross_validation': {}
        }

        # å¯ä¿¡åº¦åˆ†å¸ƒæ•°æ®
        for evaluator, stats in self.credibility_stats.items():
            if stats['scores']:
                report['credibility_distribution'][evaluator] = {
                    'count': len(stats['scores']),
                    'mean': statistics.mean(stats['scores']),
                    'median': statistics.median(stats['scores']),
                    'min': min(stats['scores']),
                    'max': max(stats['scores']),
                    'std_dev': statistics.stdev(stats['scores']) if len(stats['scores']) > 1 else 0
                }

        # ä¿å­˜æŠ¥å‘Š
        report_path = f"batch_credibility_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ‰¹é‡å¯ä¿¡åº¦åˆ†æå™¨")
    print("=" * 80)
    print("åˆ†æä¸¤ä¸ªè¯„ä¼°å™¨çš„è™šå‡å…±è¯†é£é™©å’Œå¯ä¿¡åº¦åˆ†å¸ƒ")

    analyzer = BatchCredibilityAnalyzer()

    # åŠ è½½ç»“æœ
    analyzer.load_results()

    # åˆ†æè™šå‡å…±è¯†é£é™©
    risk_analysis = analyzer.analyze_false_consensus_risks()

    # åˆ†æå¯ä¿¡åº¦åˆ†å¸ƒ
    analyzer.analyze_credibility_distribution()

    # äº¤å‰éªŒè¯åˆ†æ
    analyzer.cross_validator_analysis()

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report_path = analyzer.generate_comprehensive_report()

    print("\nâœ… åˆ†æå®Œæˆ!")
    print(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

    # å…³é”®å‘ç°æ€»ç»“
    print("\nğŸ¯ å…³é”®å‘ç°:")
    print("1. Ollamaè¯„ä¼°å™¨å­˜åœ¨JSONåºåˆ—åŒ–é”™è¯¯å¯¼è‡´å´©æºƒ")
    print("2. äº‘æ¨¡å‹è¯„ä¼°å™¨é­é‡å¤§é‡ConnectionResetError")
    print("3. ä¸¤ä¸ªè¯„ä¼°å™¨éƒ½å­˜åœ¨é«˜å¤±è´¥ç‡ï¼Œé€ æˆè™šå‡å…±è¯†é£é™©")
    print("4. å»ºè®®é‡æ–°è®¾è®¡å¯ä¿¡åº¦è¯„åˆ†æœºåˆ¶ï¼Œè€ƒè™‘å¤±è´¥ç‡æƒé‡")

if __name__ == "__main__":
    main()