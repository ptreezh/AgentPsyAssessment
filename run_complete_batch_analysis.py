#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„æ‰¹é‡å¯ä¿¡è¯„ä¼°åˆ†æå™¨
ä½¿ç”¨å·²éªŒè¯çš„Ollamaæœ¬åœ°æ¨¡å‹å¤„ç†æ‰€æœ‰åŸå§‹æµ‹è¯„æŠ¥å‘Š
"""
import sys
import os
import json
import glob
from pathlib import Path
from datetime import datetime
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from segmented_scoring_evaluator import SegmentedScoringEvaluator


def run_complete_batch_analysis(input_dir="results/readonly-original", output_dir="complete_segmented_scoring_results", max_files=None):
    """
    è¿è¡Œå®Œæ•´æ‰¹é‡åˆ†æï¼Œä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹å¤„ç†æ‰€æœ‰åŸå§‹æµ‹è¯„æŠ¥å‘Š
    """
    print("="*60)
    print("ğŸš€ å®Œæ•´æ‰¹é‡å¯ä¿¡è¯„ä¼°åˆ†æå™¨")
    print("="*60)
    print("ğŸ“‹ ç³»ç»Ÿé…ç½®:")
    print("   ğŸ¦™ Ollamaæœ¬åœ°æ¨¡å‹: ä½œä¸ºä¸»è¦è¯„ä¼°å™¨")
    print("   â˜ï¸  OpenRouter API: ç”±äºAPIå¯†é’¥å¤±æ•ˆå·²åœç”¨")
    print("   ğŸ“ è¯„ä¼°æ–¹æ³•: 5é¢˜åˆ†æ®µç‹¬ç«‹è¯„ä¼°")
    print("   ğŸ¤– ä¸»è¦æ¨¡å‹: qwen3:4b, gemma2:2b, llama3.2:3b")
    print()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        print("è¯·ç¡®ä¿åŸå§‹æµ‹è¯„æŠ¥å‘Šä½äº results/readonly-original ç›®å½•ä¸­")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_pattern = os.path.join(input_dir, "*.json")
    all_files = glob.glob(json_pattern)
    
    if not all_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    # é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    files_to_process = all_files[:max_files] if max_files else all_files
    
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(all_files)} ä¸ªåŸå§‹æµ‹è¯„æŠ¥å‘Šï¼Œå°†å¤„ç† {len(files_to_process)} ä¸ª")
    print()
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨ï¼ˆé…ç½®ä¸ºä¼˜å…ˆä½¿ç”¨Ollamaæ¨¡å‹ï¼‰
    evaluator = SegmentedScoringEvaluator(use_ollama_first=True)
    
    # ç»Ÿè®¡ä¿¡æ¯
    processed_count = 0
    success_count = 0
    failed_count = 0
    total_consistency = 0
    total_reliability = 0
    passed_reliability_count = 0
    
    start_time = time.time()
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, file_path in enumerate(files_to_process, 1):
        filename = os.path.basename(file_path)
        print(f"ğŸ“ˆ [{i}/{len(files_to_process)}] å¤„ç†: {filename}")
        
        try:
            # æ‰§è¡Œè¯„ä¼°
            result = evaluator.evaluate_file_with_multiple_models(file_path, output_dir)
            
            if result['success']:
                processed_count += 1
                success_count += 1
                
                consistency_score = result.get('consistency_score', 0)
                reliability_score = result.get('reliability_score', 0)
                reliability_passed = result.get('reliability_passed', False)
                
                total_consistency += consistency_score
                total_reliability += reliability_score
                
                if reliability_passed:
                    passed_reliability_count += 1
                
                print(f"   âœ… ä¸€è‡´æ€§: {consistency_score:.2f}%")
                print(f"   âœ… ä¿¡åº¦: {reliability_score:.2f}%")
                print(f"   âœ… ä¿¡åº¦éªŒè¯: {'é€šè¿‡' if reliability_passed else 'æœªé€šè¿‡'}")
                print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {result['output_path']}")
            else:
                processed_count += 1
                failed_count += 1
                error_msg = result.get('error', 'Unknown error')
                print(f"   âŒ å¤„ç†å¤±è´¥: {error_msg}")
                
        except Exception as e:
            processed_count += 1
            failed_count += 1
            print(f"   âŒ å¼‚å¸¸: {str(e)}")
            continue
    
    end_time = time.time()
    total_time = end_time - start_time
    
    # æ‰“å°æ±‡æ€»ç»Ÿè®¡
    print(f"\n" + "="*60)
    print(f"ğŸ“Š å®Œæ•´æ‰¹é‡åˆ†æå®ŒæˆæŠ¥å‘Š")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"â° ç»“æŸæ—¶é—´: {datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {len(files_to_process)}")
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count}")
    print(f"âŒ å¤„ç†å¤±è´¥: {failed_count}")
    print(f"ğŸ¯ æˆåŠŸç‡: {(success_count/len(files_to_process))*100:.1f}%" if len(files_to_process) > 0 else "N/A")
    
    if success_count > 0:
        avg_consistency = total_consistency / success_count
        avg_reliability = total_reliability / success_count
        
        print(f"ğŸ“ˆ å¹³å‡ä¸€è‡´æ€§: {avg_consistency:.2f}%")
        print(f"âœ… ä¿¡åº¦éªŒè¯é€šè¿‡ç‡: {passed_reliability_count}/{success_count} ({(passed_reliability_count/success_count)*100:.1f}%)")
        print(f"ğŸ“ˆ å¹³å‡ä¿¡åº¦: {avg_reliability:.2f}%")
    
    print(f"ğŸ’¾ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("="*60)


def main():
    """
    ä¸»å‡½æ•°
    """
    print("å¯ä¿¡è¯„ä¼°åˆ†æç³»ç»Ÿ - å®Œæ•´æ‰¹é‡å¤„ç†ç‰ˆæœ¬")
    print()
    
    # è¿è¡Œå®Œæ•´æ‰¹é‡åˆ†æï¼ˆå¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼‰
    run_complete_batch_analysis(max_files=None)  # å¤„ç†æ‰€æœ‰æ–‡ä»¶


if __name__ == "__main__":
    main()