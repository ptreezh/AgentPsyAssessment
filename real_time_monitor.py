#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶ç›‘æ§æ‰¹é‡åˆ†æ - æ— ç¼“å†²è¾“å‡º
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DASHSCOPE_API_KEY'] = 'sk-3f16ac9d87e34ca88bf3925c3651624f'

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def monitor_progress():
    print("ğŸ” å®æ—¶ç›‘æ§æ‰¹é‡åˆ†æè¿›åº¦...")

    try:
        # æ£€æŸ¥è¿›åº¦æ–‡ä»¶
        progress_file = Path("batch_four_model_progress.json")
        if not progress_file.exists():
            print("âŒ è¿›åº¦æ–‡ä»¶ä¸å­˜åœ¨")
            return

        # æ£€æŸ¥ç»“æœç›®å½•
        results_dir = Path("four_model_results/multi_model_results")
        if not results_dir.exists():
            print("âŒ ç»“æœç›®å½•ä¸å­˜åœ¨")
            return

        print(f"ğŸ“Š å¼€å§‹å®æ—¶ç›‘æ§...")
        print(f"â° ç›‘æ§æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # å®æ—¶ç›‘æ§å¾ªç¯
        last_processed = 0
        start_time = datetime.now()

        while True:
            try:
                # è¯»å–è¿›åº¦æ–‡ä»¶
                with open(progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)

                current_processed = progress_data.get('total_processed', 0)
                completed_files = progress_data.get('completed_files', [])
                failed_files = progress_data.get('failed_files', [])

                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°è¿›å±•
                if current_processed > last_processed:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    if elapsed > 0:
                        rate = current_processed / (elapsed / 60)  # æ–‡ä»¶/åˆ†é’Ÿ
                        eta_files = 550 - current_processed
                        eta_minutes = eta_files / rate if rate > 0 else float('inf')
                        eta_hours = eta_minutes / 60

                    print(f"\nğŸ“ˆ [{datetime.now().strftime('%H:%M:%S')}] è¿›åº¦æ›´æ–°:")
                    print(f"   å·²å®Œæˆ: {current_processed}/550 ({current_processed/550*100:.1f}%)")
                    print(f"   æˆåŠŸæ–‡ä»¶: {len(completed_files)}")
                    print(f"   å¤±è´¥æ–‡ä»¶: {len(failed_files)}")
                    print(f"   å¤„ç†é€Ÿåº¦: {rate:.2f} æ–‡ä»¶/åˆ†é’Ÿ")
                    print(f"   é¢„è®¡å‰©ä½™: {eta_minutes:.1f}åˆ†é’Ÿ ({eta_hours:.1f}å°æ—¶)")

                    # æ£€æŸ¥æœ€æ–°ç»“æœ
                    if completed_files:
                        latest_file = completed_files[-1]
                        print(f"   æœ€æ–°å®Œæˆ: {Path(latest_file).name}")

                    last_processed = current_processed

                # æ£€æŸ¥ç»“æœç›®å½•ä¸­çš„æ–‡ä»¶æ•°é‡
                try:
                    all_files = []
                    for model_dir in results_dir.iterdir():
                        if model_dir.is_dir():
                            model_files = list(model_dir.glob("*summary.json"))
                            all_files.extend(model_files)

                    print(f"   ğŸ“ ç»“æœæ–‡ä»¶æ€»æ•°: {len(all_files)}")

                    # å¦‚æœæ–‡ä»¶æ•°é‡å¢åŠ ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    if len(all_files) > last_processed * 3:  # æ¯ä¸ªæ–‡ä»¶3ä¸ªæ¨¡å‹
                        print(f"   âœ… æ£€æµ‹åˆ°æ–°ç»“æœæ–‡ä»¶")

                except:
                    pass

                # ç­‰å¾…5ç§’
                import time
                time.sleep(5)

            except KeyboardInterrupt:
                print(f"\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
                break
            except Exception as e:
                print(f"âŒ ç›‘æ§é”™è¯¯: {e}")
                time.sleep(5)

    except Exception as e:
        print(f"ğŸ’¥ ç›‘æ§å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    monitor_progress()