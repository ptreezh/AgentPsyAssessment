#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‘è¯„ä¼°å™¨åˆ†ææ¢å¤è„šæœ¬
ç”¨äºæ¢å¤ä¸­æ–­çš„æ‰¹é‡åˆ†æä»»åŠ¡ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
"""

import json
import sys
import time
import argparse
from pathlib import Path
from datetime import datetime
from cloud_segmented_analysis import CloudSegmentedPersonalityAnalyzer

class ResumeCloudAnalysis:
    """äº‘è¯„ä¼°å™¨åˆ†ææ¢å¤å™¨"""

    def __init__(self, model: str = "qwen-long", api_key: str = None):
        self.model = model
        self.api_key = api_key or "sk-ffd03518254b495b8d27e723cd413fc1"
        self.completed_files = set()
        self.failed_files = []

    def load_completed_files(self, output_dir: Path):
        """åŠ è½½å·²å®Œæˆçš„æ–‡ä»¶åˆ—è¡¨"""
        output_dir = Path(output_dir) / self.model
        if not output_dir.exists():
            return

        for file_path in output_dir.glob("*_segmented.json"):
            # æå–åŸå§‹æ–‡ä»¶å
            original_name = file_path.name.replace(f"_{self.model}_segmented.json", "")
            self.completed_files.add(original_name)

        print(f"ğŸ“‚ å‘ç° {len(self.completed_files)} ä¸ªå·²å®Œæˆçš„åˆ†ææ–‡ä»¶")

    def get_remaining_files(self, input_dir: Path) -> list[Path]:
        """è·å–å¾…åˆ†æçš„æ–‡ä»¶åˆ—è¡¨"""
        all_files = list(input_dir.glob("*.json"))
        remaining_files = []

        for file_path in all_files:
            if file_path.name not in self.completed_files:
                remaining_files.append(file_path)

        return remaining_files

    def analyze_single_file(self, input_file: Path, output_dir: Path, max_retries: int = 3) -> dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        for attempt in range(max_retries):
            try:
                print(f"ğŸ” [{attempt+1}/{max_retries}] å¼€å§‹åˆ†æ: {input_file.name}")

                # åˆ›å»ºåˆ†æå™¨
                analyzer = CloudSegmentedPersonalityAnalyzer(
                    model=self.model,
                    api_key=self.api_key
                )

                # æ‰§è¡Œåˆ†æ
                result = analyzer.analyze_full_assessment(str(input_file))

                # ä¿å­˜ç»“æœ
                output_file = output_dir / self.model / f"{input_file.stem}_{self.model}_segmented.json"
                output_file.parent.mkdir(parents=True, exist_ok=True)

                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)

                # ç”Ÿæˆæ‘˜è¦
                big5_scores = result['big_five_final_scores']
                summary = {
                    'file': str(input_file),
                    'output_file': str(output_file),
                    'model': self.model,
                    'success': True,
                    'big5_final_scores': {trait: data['final_score'] for trait, data in big5_scores.items()},
                    'mbti_type': result['mbti_assessment']['type'],
                    'total_questions': result['file_info']['total_questions'],
                    'segments_processed': result['file_info']['segments_count']
                }

                print(f"âœ… åˆ†æå®Œæˆ: {input_file.name}")
                print(f"   Big5: {summary['big5_final_scores']}")
                print(f"   MBTI: {summary['mbti_type']}")

                return summary

            except Exception as e:
                print(f"âŒ å°è¯• {attempt+1} å¤±è´¥: {input_file.name} - {e}")

                if attempt < max_retries - 1:
                    # æŒ‡æ•°é€€é¿
                    wait_time = 5 * (2 ** attempt)
                    print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"   æœ€ç»ˆå¤±è´¥: {input_file.name}")
                    error_summary = {
                        'file': str(input_file),
                        'output_file': None,
                        'model': self.model,
                        'success': False,
                        'error': str(e),
                        'big5_final_scores': {},
                        'mbti_type': None,
                        'total_questions': 0,
                        'segments_processed': 0
                    }
                    self.failed_files.append(error_summary)
                    return error_summary

    def resume_analysis(self, input_dir: Path, output_dir: Path,
                       max_files: int = None, delay_between_files: int = 3):
        """æ¢å¤åˆ†æä»»åŠ¡"""
        print(f"ğŸš€ æ¢å¤äº‘è¯„ä¼°å™¨åˆ†æä»»åŠ¡")
        print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model}")

        # åŠ è½½å·²å®Œæˆæ–‡ä»¶
        self.load_completed_files(output_dir)

        # è·å–å‰©ä½™æ–‡ä»¶
        remaining_files = self.get_remaining_files(input_dir)

        if max_files:
            remaining_files = remaining_files[:max_files]

        if not remaining_files:
            print("âœ… æ‰€æœ‰æ–‡ä»¶å·²å®Œæˆåˆ†æ")
            return

        print(f"ğŸ“Š å‰©ä½™å¾…åˆ†ææ–‡ä»¶: {len(remaining_files)}")

        results = []
        completed = 0

        for i, input_file in enumerate(remaining_files, 1):
            print(f"\nğŸ“ˆ è¿›åº¦: {i}/{len(remaining_files)} ({i/len(remaining_files)*100:.1f}%)")

            # åˆ†ææ–‡ä»¶
            result = self.analyze_single_file(input_file, output_dir)
            results.append(result)

            if result['success']:
                completed += 1

            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            if i < len(remaining_files):
                print(f"â±ï¸  ç­‰å¾… {delay_between_files} ç§’...")
                time.sleep(delay_between_files)

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(results, output_dir)

        # æœ€ç»ˆç»Ÿè®¡
        successful = sum(1 for r in results if r['success'])
        print(f"\nğŸ‰ æ¢å¤åˆ†æå®Œæˆ!")
        print(f"âœ… æœ¬æ¬¡æˆåŠŸ: {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")
        print(f"ğŸ“ å¤±è´¥æ–‡ä»¶: {len(self.failed_files)}")
        print(f"ğŸ“‚ æ€»è®¡å®Œæˆ: {len(self.completed_files) + completed}")

    def generate_summary_report(self, results: list[dict], output_dir: Path):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        successful_results = [r for r in results if r['success']]

        if not successful_results:
            print("âš ï¸  æ²¡æœ‰æˆåŠŸçš„åˆ†æç»“æœï¼Œè·³è¿‡æ±‡æ€»æŠ¥å‘Šç”Ÿæˆ")
            return

        # ç»Ÿè®¡Big5è¯„åˆ†åˆ†å¸ƒ
        big5_stats = {}
        mbti_stats = {}

        for result in successful_results:
            # Big5ç»Ÿè®¡
            for trait, score in result['big5_final_scores'].items():
                if trait not in big5_stats:
                    big5_stats[trait] = {1: 0, 3: 0, 5: 0}
                big5_stats[trait][score] += 1

            # MBTIç»Ÿè®¡
            mbti_type = result['mbti_type']
            if mbti_type not in mbti_stats:
                mbti_stats[mbti_type] = 0
            mbti_stats[mbti_type] += 1

        # ç”Ÿæˆæ±‡æ€»æ•°æ®
        summary = {
            'summary': {
                'total_files_analyzed': len(results),
                'successful': len(successful_results),
                'failed': len(self.failed_files),
                'success_rate': len(successful_results) / len(results) * 100 if results else 0,
                'model_used': self.model,
                'analysis_timestamp': datetime.now().isoformat(),
                'previously_completed': len(self.completed_files)
            },
            'big5_distribution': big5_stats,
            'mbti_distribution': mbti_stats,
            'detailed_results': results,
            'failed_files': self.failed_files
        }

        # ä¿å­˜JSONæ±‡æ€»
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        json_summary = output_path / f"resume_summary_{self.model}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_summary, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“Š æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {json_summary}")

        # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
        print(f"\nğŸ“‹ æœ¬æ¬¡åˆ†æç»Ÿè®¡:")
        print(f"ğŸ“Š Big5è¯„åˆ†åˆ†å¸ƒ:")
        for trait, scores in big5_stats.items():
            total = sum(scores.values())
            print(f"  {trait.replace('_', ' ').title()}: 1åˆ†({scores[1]}/{total}) 3åˆ†({scores[3]}/{total}) 5åˆ†({scores[5]}/{total})")

        print(f"\nğŸ§  MBTIç±»å‹åˆ†å¸ƒ:")
        for mbti_type, count in sorted(mbti_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  {mbti_type}: {count}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¢å¤äº‘è¯„ä¼°å™¨åˆ†æä»»åŠ¡')
    parser.add_argument('input_dir', default='results/results', help='è¾“å…¥ç›®å½•è·¯å¾„')
    parser.add_argument('--output', default='batch_cloud_segmented_results', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model', default='qwen-long', choices=['qwen-long', 'qwen-max'],
                       help='ä½¿ç”¨çš„äº‘æ¨¡å‹')
    parser.add_argument('--max-files', type=int, help='æœ€å¤§å¤„ç†æ–‡ä»¶æ•°')
    parser.add_argument('--delay', type=int, default=3, help='æ–‡ä»¶é—´å»¶è¿Ÿç§’æ•°')

    args = parser.parse_args()

    # åˆ›å»ºæ¢å¤åˆ†æå™¨
    analyzer = ResumeCloudAnalysis(model=args.model)

    # æ‰§è¡Œæ¢å¤åˆ†æ
    analyzer.resume_analysis(
        Path(args.input_dir),
        Path(args.output),
        max_files=args.max_files,
        delay_between_files=args.delay
    )

if __name__ == "__main__":
    main()