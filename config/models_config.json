{
  "providers": {
    "openrouter": {
      "name": "OpenRouter",
      "base_url": "https://openrouter.ai/api/v1",
      "models": {
        "anthropic/claude-3.5-sonnet": {
          "name": "claude-3.5-sonnet",
          "provider": "openrouter",
          "description": "Claude 3.5 Sonnet (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 200000,
          "pricing": { "input": 0.000003, "output": 0.000015 }
        },
        "anthropic/claude-3-opus": {
          "name": "claude-3-opus",
          "provider": "openrouter",
          "description": "Claude 3 Opus (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 200000,
          "pricing": { "input": 0.000015, "output": 0.000075 }
        },
        "anthropic/claude-3-haiku": {
          "name": "claude-3-haiku",
          "provider": "openrouter",
          "description": "Claude 3 Haiku (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 200000,
          "pricing": { "input": 0.00000025, "output": 0.00000125 }
        },
        "openai/gpt-4o": {
          "name": "gpt-4o",
          "provider": "openrouter",
          "description": "GPT-4o (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 128000,
          "pricing": { "input": 0.000005, "output": 0.000015 }
        },
        "openai/gpt-4-turbo": {
          "name": "gpt-4-turbo",
          "provider": "openrouter",
          "description": "GPT-4 Turbo (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 128000,
          "pricing": { "input": 0.00001, "output": 0.00003 }
        },
        "google/gemini-pro": {
          "name": "gemini-pro",
          "provider": "openrouter",
          "description": "Gemini Pro (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 32768,
          "pricing": { "input": 0.0000005, "output": 0.0000015 }
        },
        "meta-llama/llama-3.1-405b-instruct": {
          "name": "llama-3.1-405b-instruct",
          "provider": "openrouter",
          "description": "Llama 3.1 405B Instruct (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 131072,
          "pricing": { "input": 0.0000027, "output": 0.0000027 }
        },
        "meta-llama/llama-3.1-70b-instruct": {
          "name": "llama-3.1-70b-instruct",
          "provider": "openrouter",
          "description": "Llama 3.1 70B Instruct (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 131072,
          "pricing": { "input": 0.00000035, "output": 0.00000035 }
        },
        "mistralai/mistral-large": {
          "name": "mistral-large",
          "provider": "openrouter",
          "description": "Mistral Large (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 32768,
          "pricing": { "input": 0.000002, "output": 0.000006 }
        },
        "qwen/qwen-2.5-72b-instruct": {
          "name": "qwen-2.5-72b-instruct",
          "provider": "openrouter",
          "description": "Qwen 2.5 72B Instruct (via OpenRouter)",
          "temperature": 0.7,
          "max_tokens": 4096,
          "context_window": 32768,
          "pricing": { "input": 0.000001, "output": 0.000002 }
        }
      }
    },
    "direct": {
      "name": "Direct API",
      "models": {
        "openai": {
          "gpt-4": {
            "name": "gpt-4",
            "provider": "direct",
            "description": "GPT-4 (Direct OpenAI API)",
            "base_url": "https://api.openai.com/v1",
            "temperature": 0.7,
            "max_tokens": 4096,
            "context_window": 8192
          },
          "gpt-4o": {
            "name": "gpt-4o",
            "provider": "direct",
            "description": "GPT-4o (Direct OpenAI API)",
            "base_url": "https://api.openai.com/v1",
            "temperature": 0.7,
            "max_tokens": 4096,
            "context_window": 128000
          }
        },
        "anthropic": {
          "claude-3-5-sonnet": {
            "name": "claude-3-5-sonnet",
            "provider": "direct",
            "description": "Claude 3.5 Sonnet (Direct Anthropic API)",
            "base_url": "https://api.anthropic.com",
            "temperature": 0.7,
            "max_tokens": 4096,
            "context_window": 200000
          }
        }
      }
    },
    "ollama": {
      "name": "Ollama Local",
      "base_url": "http://localhost:11434",
      "models": {
        "llama3.1": {
          "name": "llama3.1",
          "provider": "ollama",
          "description": "Llama 3.1 (Local Ollama)",
          "temperature": 0.7,
          "max_tokens": 4096
        },
        "mistral": {
          "name": "mistral",
          "provider": "ollama",
          "description": "Mistral (Local Ollama)",
          "temperature": 0.7,
          "max_tokens": 4096
        },
        "qwen2.5": {
          "name": "qwen2.5",
          "provider": "ollama",
          "description": "Qwen 2.5 (Local Ollama)",
          "temperature": 0.7,
          "max_tokens": 4096
        }
      }
    }
  },
  "evaluation_configs": {
    "high_quality": {
      "temperature": 0.1,
      "max_tokens": 4096,
      "top_p": 0.9,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "timeout": 300
    },
    "creative": {
      "temperature": 0.8,
      "max_tokens": 4096,
      "top_p": 0.95,
      "frequency_penalty": 0.1,
      "presence_penalty": 0.1,
      "timeout": 300
    },
    "balanced": {
      "temperature": 0.5,
      "max_tokens": 4096,
      "top_p": 0.9,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "timeout": 180
    },
    "fast": {
      "temperature": 0.3,
      "max_tokens": 2048,
      "top_p": 0.8,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "timeout": 60
    }
  },
  "default_settings": {
    "provider": "openrouter",
    "model": "anthropic/claude-3.5-sonnet",
    "config": "high_quality",
    "retry_attempts": 3,
    "retry_delay": 1,
    "rate_limiting": {
      "requests_per_minute": 60,
      "requests_per_hour": 3000
    }
  }
}