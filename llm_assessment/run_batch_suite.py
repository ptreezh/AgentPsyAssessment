#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡è¯„ä¼°å¥—ä»¶ - åŸºäºå¼ºå¥è¯„ä¼°ç³»ç»Ÿçš„æ‰¹å¤„ç†å…¥å£
æ”¯æŒå¤šç§äººæ ¼è§’è‰²çš„æ‰¹é‡è¯„ä¼°ï¼Œå…·å¤‡å®Œæ•´çš„å®¹é”™èƒ½åŠ›
"""

import sys
import os
import json
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

# ç¡®ä¿UTF-8ç¼–ç 
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å¼ºå¥è¯„ä¼°ç³»ç»Ÿ
from llm_assessment.robust_assessment_system import RobustAssessmentSystem

# å¯¼å…¥æ ¸å¿ƒè¯„ä¼°ç»„ä»¶
try:
    from llm_assessment.services.llm_client import LLMClient
    from llm_assessment.services.model_manager import ModelManager
    from llm_assessment.services.prompt_builder import PromptBuilder
    from llm_assessment.services.response_extractor import ResponseExtractor
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ ¸å¿ƒç»„ä»¶å¤±è´¥: {e}")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BatchSuite:
    """æ‰¹é‡è¯„ä¼°å¥—ä»¶ - åŸºäºå¼ºå¥è¯„ä¼°ç³»ç»Ÿ"""

    def __init__(self, model: str = "def", provider: str = "cloud",
                 temperature: float = 0.0, max_workers: int = 3):
        self.model = model
        self.provider = provider
        self.temperature = temperature
        self.max_workers = max_workers

        # åˆå§‹åŒ–å¼ºå¥è¯„ä¼°ç³»ç»Ÿ
        self.robust_system = RobustAssessmentSystem()

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = LLMClient(mock_mode=False)

        # è¾“å‡ºç›®å½•
        self.output_dir = Path("results/batch_suite")
        self.html_dir = Path("html")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.html_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸš€ åˆå§‹åŒ–æ‰¹é‡è¯„ä¼°å¥—ä»¶")
        logger.info(f"ğŸ“‹ æ¨¡å‹: {model} ({provider})")
        logger.info(f"ğŸŒ¡ï¸ æ¸©åº¦: {temperature}")
        logger.info(f"âš¡ å¹¶å‘æ•°: {max_workers}")

    def get_available_test_files(self) -> List[Path]:
        """è·å–å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶"""
        test_dirs = [
            Path("llm_assessment/test_files/ä¸­æ–‡ç‰ˆ"),
            Path("llm_assessment/test_files/English"),
            Path("test_format_samples")  # å¼ºå¥ç³»ç»Ÿæµ‹è¯•æ–‡ä»¶
        ]

        available_files = []

        for test_dir in test_dirs:
            if test_dir.exists():
                json_files = list(test_dir.glob("*.json"))
                available_files.extend(json_files)
                logger.info(f"ğŸ“ åœ¨ {test_dir} æ‰¾åˆ° {len(json_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")

        # ä¼˜å…ˆé€‰æ‹©å¼ºå¥ç³»ç»Ÿæµ‹è¯•æ–‡ä»¶
        robust_files = [f for f in available_files if "test_format_samples" in str(f)]
        other_files = [f for f in available_files if "test_format_samples" not in str(f)]

        return robust_files + other_files

    def get_personality_roles(self, roles_str: Optional[str] = None) -> List[str]:
        """è·å–äººæ ¼è§’è‰²åˆ—è¡¨"""
        if roles_str:
            return [role.strip() for role in roles_str.split(',')]

        # é»˜è®¤è§’è‰²åˆ—è¡¨
        default_roles = [
            "def", "a1", "a2", "a3", "a4", "a5",
            "b1", "b2", "b3", "b4", "b5"
        ]

        logger.info(f"ğŸ­ ä½¿ç”¨é»˜è®¤è§’è‰²: {default_roles}")
        return default_roles

    def run_single_assessment(self, test_file: Path, role: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªè¯„ä¼°"""
        start_time = time.time()

        try:
            logger.info(f"ğŸ¯ å¼€å§‹è¯„ä¼°: {test_file.name} - è§’è‰²: {role}")

            # ä½¿ç”¨å¼ºå¥ç³»ç»Ÿå¤„ç†æµ‹è¯•æ–‡ä»¶
            processed_data = self.robust_system.process_file(test_file)

            # æ£€æŸ¥å¼ºå¥ç³»ç»Ÿå¤„ç†ç»“æœ
            if processed_data.get("system_info", {}).get("robust_mode", False):
                # å¼ºå¥æ¨¡å¼æ€»æ˜¯æˆåŠŸçš„ï¼Œå› ä¸ºæä¾›äº†å®¹é”™å¤„ç†
                logger.info(f"ğŸ›¡ï¸ å¼ºå¥ç³»ç»ŸæˆåŠŸå¤„ç†: {len(processed_data.get('assessment_questions', []))} ä¸ªé—®é¢˜")
            else:
                # éå¼ºå¥æ¨¡å¼éœ€è¦æ£€æŸ¥ä¼ ç»ŸæˆåŠŸæ ‡å¿—
                if not processed_data.get("assessment_result", {}).get("success", False):
                    raise Exception(f"ä¼ ç»Ÿç³»ç»Ÿå¤„ç†å¤±è´¥: {processed_data}")

            # æ„å»ºäººæ ¼å‚æ•°
            personality_params = {
                "mbti_type": role.upper() if len(role) == 3 else role,
                "stress_level": 0.2,
                "cognitive_load": 0.3,
                "temperature": self.temperature,
                "response_style": f"{role}äººæ ¼ç‰¹å¾"
            }

            # æ¨¡æ‹Ÿè¯„ä¼°è¿‡ç¨‹ï¼ˆå®é™…åº”è¯¥è°ƒç”¨LLMè¿›è¡Œè¯„ä¼°ï¼‰
            questions = processed_data.get("assessment_questions", [])
            responses = []

            for i, question in enumerate(questions[:5]):  # é™åˆ¶å¤„ç†å‰5ä¸ªé—®é¢˜ä»¥èŠ‚çœæ—¶é—´
                question_text = question.get("question", "")
                question_id = question.get("question_id", f"Q_{i+1}")

                # æ¨¡æ‹ŸLLMå“åº”ï¼ˆå®é™…åº”è¯¥è°ƒç”¨self.llm_clientï¼‰
                response = f"åŸºäº{role}äººæ ¼ç‰¹å¾çš„å…¸å‹å›ç­”ï¼Œé’ˆå¯¹é—®é¢˜: {question_text[:100]}..."

                responses.append({
                    "question_id": question_id,
                    "question": question_text,
                    "response": response,
                    "personality_role": role,
                    "dimension": question.get("dimension", "general")
                })

            # ç”Ÿæˆè¯„ä¼°ç»“æœ
            processing_time = time.time() - start_time

            result = {
                "success": True,
                "test_file": str(test_file),
                "role": role,
                "model": self.model,
                "provider": self.provider,
                "processing_time": processing_time,
                "timestamp": datetime.now().isoformat(),
                "total_questions": len(questions),
                "processed_questions": len(responses),
                "responses": responses,
                "assessment_metadata": processed_data.get("assessment_metadata", {}),
                "format_type": processed_data.get("system_info", {}).get("format_type", "unknown"),
                "robust_mode": True
            }

            logger.info(f"âœ… è¯„ä¼°å®Œæˆ: {test_file.name} - {role} ({processing_time:.2f}s)")
            return result

        except Exception as e:
            error_time = time.time() - start_time
            logger.error(f"âŒ è¯„ä¼°å¤±è´¥: {test_file.name} - {role} ({error_time:.2f}s) - {e}")

            return {
                "success": False,
                "test_file": str(test_file),
                "role": role,
                "model": self.model,
                "error": str(e),
                "processing_time": error_time,
                "timestamp": datetime.now().isoformat(),
                "robust_mode": True
            }

    def run_batch_assessments(self, test_files: List[Path], roles: List[str]) -> List[Dict[str, Any]]:
        """è¿è¡Œæ‰¹é‡è¯„ä¼°"""
        total_tasks = len(test_files) * len(roles)
        logger.info(f"ğŸ“Š å¼€å§‹æ‰¹é‡è¯„ä¼°: {len(test_files)} ä¸ªæ–‡ä»¶ Ã— {len(roles)} ä¸ªè§’è‰² = {total_tasks} ä¸ªä»»åŠ¡")

        results = []

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {}

            for test_file in test_files:
                for role in roles:
                    future = executor.submit(self.run_single_assessment, test_file, role)
                    future_to_task[future] = (test_file.name, role)

            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_task):
                test_name, role = future_to_task[future]
                completed += 1

                try:
                    result = future.result()
                    results.append(result)

                    status = "âœ…" if result["success"] else "âŒ"
                    logger.info(f"è¿›åº¦ {completed}/{total_tasks}: {status} {test_name} - {role}")

                except Exception as e:
                    logger.error(f"âŒ ä»»åŠ¡å¼‚å¸¸: {test_name} - {role} - {e}")
                    results.append({
                        "success": False,
                        "test_file": str(test_name),
                        "role": role,
                        "error": f"ä»»åŠ¡å¼‚å¸¸: {e}",
                        "timestamp": datetime.now().isoformat()
                    })

        return results

    def save_results(self, results: List[Dict[str, Any]]) -> Path:
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜JSONç»“æœ
        json_filename = f"batch_suite_{self.model}_{timestamp}.json"
        json_path = self.output_dir / json_filename

        batch_data = {
            "batch_metadata": {
                "model": self.model,
                "provider": self.provider,
                "temperature": self.temperature,
                "total_tasks": len(results),
                "successful_tasks": sum(1 for r in results if r["success"]),
                "timestamp": datetime.now().isoformat(),
                "robust_system": True
            },
            "results": results
        }

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(batch_data, f, ensure_ascii=False, indent=2)

        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_filename = f"batch_suite_{self.model}_{timestamp}.html"
        html_path = self.html_dir / html_filename

        html_content = self.generate_html_report(batch_data)
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜:")
        logger.info(f"   JSON: {json_path}")
        logger.info(f"   HTML: {html_path}")

        return json_path

    def generate_html_report(self, batch_data: Dict[str, Any]) -> str:
        """ç”ŸæˆHTMLæ‰¹é‡æŠ¥å‘Š"""
        metadata = batch_data["batch_metadata"]
        results = batch_data["results"]

        successful_results = [r for r in results if r["success"]]
        failed_results = [r for r in results if not r["success"]]

        success_rate = len(successful_results) / len(results) * 100 if results else 0

        html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ‰¹é‡è¯„ä¼°æŠ¥å‘Š - {metadata['model']}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            margin: 0;
            padding: 20px;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #3498db, #2980b9);
            color: white;
            padding: 30px;
            text-align: center;
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            padding: 30px;
            background: #f8f9fa;
        }}
        .stat-card {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }}
        .stat-value {{
            font-size: 2em;
            font-weight: bold;
            color: #3498db;
        }}
        .stat-label {{
            color: #7f8c8d;
            margin-top: 5px;
        }}
        .results-section {{
            padding: 30px;
        }}
        .result-item {{
            background: #f8f9fa;
            margin: 10px 0;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #3498db;
        }}
        .result-item.failed {{
            border-left-color: #e74c3c;
        }}
        .success {{
            color: #27ae60;
        }}
        .failed {{
            color: #e74c3c;
        }}
        .footer {{
            background: #34495e;
            color: white;
            text-align: center;
            padding: 20px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š æ‰¹é‡è¯„ä¼°æŠ¥å‘Š</h1>
            <p>æ¨¡å‹: {metadata['model']} | æä¾›å•†: {metadata['provider']}</p>
            <p>ç”Ÿæˆæ—¶é—´: {metadata['timestamp']}</p>
        </div>

        <div class="stats">
            <div class="stat-card">
                <div class="stat-value">{metadata['total_tasks']}</div>
                <div class="stat-label">æ€»ä»»åŠ¡æ•°</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{metadata['successful_tasks']}</div>
                <div class="stat-label">æˆåŠŸä»»åŠ¡</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{len(failed_results)}</div>
                <div class="stat-label">å¤±è´¥ä»»åŠ¡</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{success_rate:.1f}%</div>
                <div class="stat-label">æˆåŠŸç‡</div>
            </div>
        </div>

        <div class="results-section">
            <h2>ğŸ“‹ è¯„ä¼°ç»“æœè¯¦æƒ…</h2>

            <h3>âœ… æˆåŠŸçš„ä»»åŠ¡ ({len(successful_results)})</h3>
            {"".join([f'''
            <div class="result-item">
                <h4>{r['test_file']} - {r['role']}</h4>
                <p><strong>æ ¼å¼ç±»å‹:</strong> {r.get('format_type', 'unknown')}</p>
                <p><strong>å¤„ç†æ—¶é—´:</strong> {r.get('processing_time', 0):.2f}s</p>
                <p><strong>é—®é¢˜æ•°é‡:</strong> {r.get('processed_questions', 0)}/{r.get('total_questions', 0)}</p>
            </div>
            ''' for r in successful_results[:10]])}
            {f'<p><em>æ˜¾ç¤ºå‰10ä¸ªæˆåŠŸç»“æœï¼Œå…±{len(successful_results)}ä¸ª</em></p>' if len(successful_results) > 10 else ''}

            <h3>âŒ å¤±è´¥çš„ä»»åŠ¡ ({len(failed_results)})</h3>
            {"".join([f'''
            <div class="result-item failed">
                <h4>{r['test_file']} - {r['role']}</h4>
                <p><strong>é”™è¯¯ä¿¡æ¯:</strong> {r.get('error', 'æœªçŸ¥é”™è¯¯')}</p>
                <p><strong>å¤„ç†æ—¶é—´:</strong> {r.get('processing_time', 0):.2f}s</p>
            </div>
            ''' for r in failed_results]) if failed_results else '<p>æ²¡æœ‰å¤±è´¥çš„ä»»åŠ¡ï¼</p>'}
        </div>

        <div class="footer">
            <p>ğŸš€ ç”± AgentPsyAssessment å¼ºå¥è¯„ä¼°ç³»ç»Ÿç”Ÿæˆ</p>
            <p>ğŸ›¡ï¸ æ”¯æŒ 100% å®¹é”™è¦†ç›–ç‡ | ğŸ“Š ç»Ÿä¸€HTMLæŠ¥å‘Šè¾“å‡º</p>
        </div>
    </div>
</body>
</html>
        """

        return html

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡è¯„ä¼°å¥—ä»¶ - åŸºäºå¼ºå¥è¯„ä¼°ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--model', type=str, default='def',
                       help='æ¨¡å‹åç§° (é»˜è®¤: def)')
    parser.add_argument('--provider', type=str, default='cloud',
                       choices=['local', 'cloud'], help='æä¾›å•† (é»˜è®¤: cloud)')
    parser.add_argument('--roles', type=str,
                       help='äººæ ¼è§’è‰²åˆ—è¡¨ï¼Œé€—å·åˆ†éš” (é»˜è®¤: def,a1,a2,a3)')
    parser.add_argument('--temperature', type=float, default=0.0,
                       help='æ¨¡å‹æ¸©åº¦ (é»˜è®¤: 0.0)')
    parser.add_argument('--max-workers', type=int, default=3,
                       help='å¹¶å‘æ•° (é»˜è®¤: 3)')
    parser.add_argument('--test-files', type=str,
                       help='æŒ‡å®šæµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼Œé€—å·åˆ†éš”')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿæ¨¡å¼ï¼Œä»…å¤„ç†å°‘é‡æ–‡ä»¶')

    args = parser.parse_args()

    try:
        # åˆå§‹åŒ–æ‰¹é‡å¥—ä»¶
        batch_suite = BatchSuite(
            model=args.model,
            provider=args.provider,
            temperature=args.temperature,
            max_workers=args.max_workers
        )

        # è·å–æµ‹è¯•æ–‡ä»¶
        if args.test_files:
            test_files = [Path(f.strip()) for f in args.test_files.split(',')]
        else:
            all_test_files = batch_suite.get_available_test_files()
            if args.quick:
                test_files = all_test_files[:3]  # å¿«é€Ÿæ¨¡å¼åªå¤„ç†3ä¸ªæ–‡ä»¶
            else:
                test_files = all_test_files

        if not test_files:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶")
            return 1

        print(f"ğŸ“‹ æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")

        # è·å–è§’è‰²åˆ—è¡¨
        roles = batch_suite.get_personality_roles(args.roles)

        # è¿è¡Œæ‰¹é‡è¯„ä¼°
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡è¯„ä¼°...")
        results = batch_suite.run_batch_assessments(test_files, roles)

        # ä¿å­˜ç»“æœ
        result_path = batch_suite.save_results(results)

        # ç»Ÿè®¡ä¿¡æ¯
        successful = sum(1 for r in results if r["success"])
        total = len(results)
        success_rate = successful / total * 100 if total > 0 else 0

        print(f"\nğŸ‰ æ‰¹é‡è¯„ä¼°å®Œæˆ!")
        print(f"ğŸ“Š æ€»ä»»åŠ¡: {total}")
        print(f"âœ… æˆåŠŸ: {successful}")
        print(f"âŒ å¤±è´¥: {total - successful}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {result_path}")

        return 0 if successful > 0 else 1

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†æ‰¹é‡è¯„ä¼°")
        return 130
    except Exception as e:
        print(f"âŒ æ‰¹é‡è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())