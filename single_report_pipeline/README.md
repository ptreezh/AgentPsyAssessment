# 单文件测评流水线 (Single Report Pipeline)

## 项目概述

本项目是一个透明化的单文件测评流水线系统，专门用于处理人工智能代理的大五人格测评报告。系统通过多模型独立评估、争议解决、反向计分处理等机制，生成可信的人格评估结果。

## 核心特性

### 多模型评估
- 使用3个不同品牌的>3B参数本地模型进行独立评估
- 为每道题生成完整的评估上下文
- 基于行为表现进行1-3-5评分

### 争议解决机制
- 自动检测模型评分中的分歧
- 对分歧题目追加额外模型重新评估
- 基于多数决策原则确定最终评分

### 反向计分处理
- 自动识别包含"(Reversed)"标记的反向计分题目
- 在最终汇总时正确转换评分（1↔5）
- 确保人格特质水平解释的一致性

### 透明化处理
- 详细记录每道题的处理过程
- 展示每个模型的评分结果和理由
- 明确标识争议解决过程
- 提供最终得分计算的完整路径

## 系统架构

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   输入解析      │────│  上下文生成      │────│  多模型评估     │
│  (JSON格式)     │    │  (完整上下文)    │    │  (3个模型)      │
└─────────────────┘    └──────────────────┘    └─────────────────┘
                                   │
                                   ▼
                        ┌──────────────────┐    ┌─────────────────┐
                        │  一致性检测      │────│  争议解决       │
                        │  (分歧识别)      │    │  (追加模型)     │
                        └──────────────────┘    └─────────────────┘
                                   │
                                   ▼
                        ┌──────────────────┐    ┌─────────────────┐
                        │  反向计分处理    │────│  大五计算       │
                        │  (分数转换)      │    │  (最终得分)     │
                        └──────────────────┘    └─────────────────┘
                                   │
                                   ▼
                        ┌──────────────────┐
                        │   输出报告       │
                        │  (详细结果)      │
                        └──────────────────┘
```

## 反向计分逻辑

### 核心原理
反向计分题描述的是**低特质行为**，因此：
- **同意反向描述** = 低真实特质水平
- **不同意反向描述** = 高真实特质水平

### 处理机制
```
题目: C6: (Reversed) 我经常忘记把东西放回原处
维度: Conscientiousness (尽责性)

被试回答: "我会将物品放回原位"
↓
模型评估: 高尽责性行为 → 评分1分
↓
反向转换: 1分 → 5分 (因为不同意"经常忘记"描述)
↓
真实特质: 高尽责性 (5分)
```

### 转换规则
| 行为评分 | 含义 | 反向转换 | 真实特质水平 |
|---------|------|----------|-------------|
| 1分 | 高特质行为 | → 5分 | 高特质 |
| 3分 | 中等特质行为 | → 3分 | 中等特质 |
| 5分 | 低特质行为 | → 1分 | 低特质 |

## 安装和使用

### 环境要求
- Python 3.8+
- Ollama 服务
- 本地模型仓库

### 安装步骤
```bash
# 启动Ollama服务
ollama serve

# 下载所需模型
ollama pull qwen3:8b
ollama pull deepseek-r1:8b
ollama pull mistral-nemo:latest
ollama pull llama3:latest
ollama pull gemma3:latest

# 安装依赖
pip install ollama numpy pandas
```

### 使用方法
```bash
# 处理单个测评报告
python main.py path/to/assessment.json

# 运行演示模式
python main.py --demo

# 指定输出目录
python main.py path/to/assessment.json --output-dir ./results
```

## 输出格式

系统生成详细的JSON格式输出，包含：

### 基本信息
```json
{
  "file_path": "测评报告路径",
  "big5_scores": {
    "openness_to_experience": 3.2,
    "conscientiousness": 4.1,
    "extraversion": 2.8,
    "agreeableness": 3.9,
    "neuroticism": 2.1
  },
  "mbti_type": "ISTJ"
}
```

### 详细处理过程
```json
{
  "question_results": [
    {
      "question_id": "AGENT_B5_C6",
      "final_scores": {
        "conscientiousness": 5
      },
      "is_reversed": true,
      "models_used": ["qwen3:8b", "deepseek-r1:8b"],
      "resolution_rounds": 0
    }
  ]
}
```

## 质量保证

### 可信度机制
1. **多模型评估**: 3个不同品牌模型独立评估
2. **争议解决**: 分歧题目追加评估
3. **多数决策**: 基于中位数确定最终评分
4. **反向验证**: 正确处理反向计分转换

### 错误处理
- 模型调用失败自动重试
- 评分解析失败使用默认值
- 系统异常记录详细日志

## 项目结构

```
single_report_pipeline/
├── context_generator.py      # 上下文生成器
├── input_parser.py            # 输入解析器
├── reverse_scoring_processor.py  # 反向计分处理器
├── transparent_pipeline.py    # 透明化流水线
├── main.py                   # 主程序
├── README.md                 # 项目说明
└── spec.md                   # 技术规范
```

## 文档资源

- [`spec.md`](spec.md) - 详细技术规范
- [`FINAL_DOCUMENTATION.md`](FINAL_DOCUMENTATION.md) - 完整技术文档
- [`USAGE_EXAMPLE.py`](USAGE_EXAMPLE.py) - 使用示例

## 开发指南

### 扩展模型
系统支持添加新的评估模型：
- 修改配置文件添加新模型
- 自动检测模型可用性
- 负载均衡分配评估任务

### 功能扩展
- 支持其他人格模型（如MBTI、九型人格）
- 添加可视化报告生成功能
- 集成数据库存储历史结果

## 贡献

欢迎提交Issue和Pull Request来改进本项目。

## 许可证

MIT License