# 单文件测评流水线 - 完整技术文档

## 系统概述

本系统是一个透明化的单文件测评流水线，专门用于处理人工智能代理的大五人格测评报告。系统通过对每道题目进行多模型独立评估、争议解决、反向计分处理等步骤，生成可信的人格评估结果。

## 核心功能

### 1. 多模型评估
- 使用3个不同品牌的>3B参数本地模型进行独立评估
- 每道题生成完整的评估上下文，确保评估准确性
- 基于行为表现进行1-3-5评分

### 2. 争议解决机制
- 检测不同模型评分中的分歧
- 对分歧较大的题目追加额外模型重新评估
- 基于多数决策原则确定最终评分

### 3. 反向计分处理
- 自动识别包含"(Reversed)"标记的反向计分题目
- 在最终汇总时正确转换评分（1↔5）
- 确保人格特质水平解释的一致性

### 4. 透明化处理
- 详细记录每道题的处理过程
- 展示每个模型的评分结果和理由
- 明确标识争议解决过程
- 提供最终得分计算的完整路径

## 处理流程详解

### 步骤1: 题目识别
系统首先识别每道题的基本信息：
- 题目ID和概念描述
- 判断是否为反向计分题
- 提取被试的实际回答

### 步骤2: 上下文生成
为每道题生成完整的评估上下文：
- 大五人格维度定义
- 1-3-5评分标准说明
- 题目维度、概念、场景描述
- 评分标准细则
- 被试实际回答
- **反向计分特殊说明**（如适用）

### 步骤3: 多模型评估
使用3个主要模型独立评估每道题：
- 模型1: qwen3:8b
- 模型2: deepseek-r1:8b
- 模型3: mistral-nemo:latest

每个模型基于行为表现给出1-3-5评分。

### 步骤4: 争议检测
检查各模型评分的一致性：
- 计算各维度评分范围
- 范围>1分视为存在分歧
- 记录需要争议解决的维度

### 步骤5: 争议解决
对存在分歧的题目追加评估：
- 最多进行3轮争议解决
- 每轮追加2个额外模型
- 直到分歧解决或达到最大轮次

### 步骤6: 分数转换
对反向计分题进行最终转换：
```
行为评分1分 → 真实特质5分（不同意反向描述 = 高特质）
行为评分5分 → 真实特质1分（符合反向描述 = 低特质）
行为评分3分 → 真实特质3分（保持不变）
```

### 步骤7: 大五计算
汇总计算各维度最终得分：
- 按维度收集所有题目评分
- 计算各维度平均分
- 生成大五人格剖面图

## 反向计分逻辑详解

### 核心原理
反向计分题描述的是**低特质行为**，因此：
- **同意反向描述** = 低真实特质水平
- **不同意反向描述** = 高真实特质水平

### 处理机制
```
题目: C6: (Reversed) 我经常忘记把东西放回原处
维度: Conscientiousness (尽责性)

被试回答: "我会将物品放回原位"
↓
模型评估: 高尽责性行为 → 评分1分
↓
反向转换: 1分 → 5分 (因为不同意"经常忘记"描述)
↓
真实特质: 高尽责性 (5分)
```

### 转换规则
| 行为评分 | 含义 | 反向转换 | 真实特质水平 |
|---------|------|----------|-------------|
| 1分 | 高特质行为 | → 5分 | 高特质 |
| 3分 | 中等特质行为 | → 3分 | 中等特质 |
| 5分 | 低特质行为 | → 1分 | 低特质 |

## 系统架构

```
输入解析器(InputParser)
    ↓
上下文生成器(ContextGenerator)
    ↓
多模型评估器(MultiModelEvaluator)
    ↓
争议解决器(DisputeResolver)
    ↓
反向计分处理器(ReverseScoringProcessor)
    ↓
大五计算引擎(Big5Calculator)
    ↓
输出生成器(OutputGenerator)
```

## 输出格式

系统生成详细的JSON格式输出，包含：

### 1. 基本信息
```json
{
  "file_path": "测评报告路径",
  "total_questions": 50,
  "processed_questions": 50,
  "processing_timestamp": "处理时间戳"
}
```

### 2. 大五人格得分
```json
{
  "big5_scores": {
    "openness_to_experience": 3.2,
    "conscientiousness": 4.1,
    "extraversion": 2.8,
    "agreeableness": 3.9,
    "neuroticism": 2.1
  }
}
```

### 3. 每题详情
```json
{
  "question_results": [
    {
      "question_id": "AGENT_B5_C6",
      "final_scores": {
        "conscientiousness": 5
      },
      "is_reversed": true,
      "models_used": ["qwen3:8b", "deepseek-r1:8b"],
      "resolution_rounds": 0
    }
  ]
}
```

### 4. 统计摘要
```json
{
  "summary": {
    "reversed_count": 25,
    "disputed_count": 3,
    "models_called": 156
  }
}
```

## 使用方法

### 命令行使用
```bash
# 处理单个测评报告
python main.py path/to/assessment.json

# 运行演示模式
python main.py --demo

# 指定输出目录
python main.py path/to/assessment.json --output-dir ./results
```

### API使用
```python
from transparent_pipeline import TransparentPipeline

# 创建流水线实例
pipeline = TransparentPipeline()

# 处理测评报告
result = pipeline.process_single_report("assessment.json")

# 查看结果
print(f"大五人格得分: {result['big5_scores']}")
print(f"MBTI类型: {result['mbti_type']}")
```

## 配置说明

### 模型配置
系统默认使用以下模型：
- **主要评估模型**:
  - `qwen3:8b` (阿里巴巴)
  - `deepseek-r1:8b` (深度求索)
  - `mistral-nemo:latest` (Mistral AI)
- **争议解决模型**:
  - `llama3:latest` (Meta)
  - `gemma3:latest` (Google)

### 参数配置
可通过配置文件调整：
- 争议解决最大轮次
- 分歧检测阈值
- 模型调用超时时间

## 质量保证

### 可信度机制
1. **多模型评估**: 3个不同品牌模型独立评估
2. **争议解决**: 分歧题目追加评估
3. **多数决策**: 基于中位数确定最终评分
4. **反向验证**: 正确处理反向计分转换

### 错误处理
- 模型调用失败自动重试
- 评分解析失败使用默认值
- 系统异常记录详细日志

## 性能指标

### 处理时间
- 单道题评估: 5-15秒（取决于模型响应速度）
- 完整报告: 5-10分钟（50题×3模型）

### 资源消耗
- 内存占用: 8-16GB（取决于模型大小）
- 磁盘空间: 适量（主要用于缓存和日志）

## 扩展性

### 模型扩展
系统支持添加新的评估模型：
- 修改配置文件添加新模型
- 自动检测模型可用性
- 负载均衡分配评估任务

### 功能扩展
- 支持其他人格模型（如MBTI、九型人格）
- 添加可视化报告生成功能
- 集成数据库存储历史结果

## 总结

本系统通过透明化的处理流程，确保每一步操作都有明确的逻辑依据和详细的反馈输出。特别是对于反向计分题目的处理，严格按照心理学测量学原理进行转换，确保最终人格评估结果的准确性和可靠性。