#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¶…å¿«é€Ÿæ‰¹é‡åˆ†æ - æ— å»¶è¿Ÿç‰ˆæœ¬
"""

import sys
import os
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DASHSCOPE_API_KEY'] = 'sk-3f16ac9d87e34ca88bf3925c3651624f'

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def ultra_fast_analysis():
    print("ğŸš€ğŸš€ è¶…å¿«é€Ÿæ‰¹é‡åˆ†æå¯åŠ¨...")

    try:
        from batch_four_model_analysis import BatchFourModelAnalyzer

        # åˆ›å»ºè¶…å¿«åˆ†æå™¨
        analyzer = BatchFourModelAnalyzer(
            models=["qwen-max", "deepseek-v3.2-exp", "Moonshot-Kimi-K2-Instruct"]
        )

        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {', '.join(analyzer.models)}")
        print(f"âš¡âš¡ è¶…å¿«è®¾ç½®: æ— å»¶è¿Ÿï¼Œæé€Ÿæ¨¡å¼")

        # æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶
        results_dir = Path("results/results")
        if not results_dir.exists():
            print("âŒ resultsç›®å½•ä¸å­˜åœ¨")
            return

        json_files = list(results_dir.glob("*.json"))
        if not json_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
            return

        print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªæ–‡ä»¶")

        # æ£€æŸ¥æ–­ç‚¹ä¿¡æ¯
        if analyzer.load_progress():
            print(f"ğŸ“‚ å‘ç°æ–­ç‚¹ç»§ç»­ä¿¡æ¯:")
            print(f"   å·²å®Œæˆ: {len(analyzer.completed_files)} ä¸ªæ–‡ä»¶")
            print(f"   å¤±è´¥: {len(analyzer.failed_files)} ä¸ªæ–‡ä»¶")
        else:
            print("ğŸ“‚ æœªå‘ç°æ–­ç‚¹ä¿¡æ¯ï¼Œä»å¤´å¼€å§‹")

        # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
        remaining_files = [f for f in json_files if str(f) not in analyzer.completed_files and str(f) not in analyzer.failed_files]

        print(f"ğŸ“Š å‰©ä½™å¾…å¤„ç†æ–‡ä»¶: {len(remaining_files)} ä¸ª")

        if not remaining_files:
            print("âœ… æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæˆ")
            return

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("four_model_results")
        output_dir.mkdir(exist_ok=True)

        # è¶…å¿«è¿›åº¦å›è°ƒ
        def ultra_fast_progress_callback(completed, total, result):
            success_rate = sum(1 for r in analyzer.results if r.get('success', False)) / len(analyzer.results) * 100 if analyzer.results else 0
            confidences = [r.get('confidence_analysis', {}).get('overall_confidence', 0) for r in analyzer.results if r.get('success', False)]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            completed_in_batch = len(analyzer.completed_files) + len(analyzer.failed_files)
            progress_pct = completed_in_batch/total*100
            eta_hours = (total - completed_in_batch) * 0.1 / 3600 if completed_in_batch > 0 else 0  # ä¼°ç®—å®Œæˆæ—¶é—´
            print(f"ğŸš€ğŸš€ è¶…å¿«è¿›åº¦: {completed_in_batch}/{total} ({progress_pct:.1f}%) - æˆåŠŸç‡: {success_rate:.1f}% - ç½®ä¿¡åº¦: {avg_confidence:.1f}% - é¢„è®¡å‰©ä½™: {eta_hours:.1f}å°æ—¶")

        print(f"\nâš¡âš¡ å¼€å§‹è¶…å¿«æ‰¹é‡åˆ†æ...")
        print(f"ğŸƒâ€â™‚ï¸ğŸƒâ€â™€ï¸ æ— å»¶è¿Ÿï¼Œæé€Ÿå¤„ç†")

        results = analyzer.analyze_batch(
            remaining_files,
            output_dir,
            progress_callback=ultra_fast_progress_callback,
            delay_between_files=0  # å®Œå…¨æ— å»¶è¿Ÿ
        )

        # ç”Ÿæˆæœ€ç»ˆæ±‡æ€»
        successful = sum(1 for r in results if r['success'])
        print(f"\nğŸ¯ğŸ¯ è¶…å¿«æ‰¹é‡åˆ†æå®Œæˆ:")
        print(f"âœ… æˆåŠŸ: {successful}/{len(results)}")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

        if successful > 0:
            analyzer.generate_summary_report(results, output_dir)
            print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {output_dir}/four_model_batch_summary.md")

            # ç”Ÿæˆå½“å‰è¿›åº¦æ±‡æ€»
            os.system("python generate_current_summary.py")

    except Exception as e:
        print(f"ğŸ’¥ è¶…å¿«æ‰¹é‡åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    ultra_fast_analysis()